[["index.html", "Data Preparation and Analysis 1 Experiment Overview", " Data Preparation and Analysis Anna Makova (under supervision of Dr. Jacob Bellmund) 05/08/2021 1 Experiment Overview This experiment was conducted to investigate the development of spatial memory in 8- to 15-year-old children and adolescents. Participants navigated throughout a circular arena with a landmark and extra-maze, orientation cues created in Unity environment. Participants learned positions of 4 objects from which 2 were landmark-bound and 2 were boundary-bound. After block 1, landmark and landmark-dependent objects changed their position and participants had to notice an dlearn new positions. "],["data-preparation.html", "2 Data Preparation 2.1 Setup 2.2 Summary and Angle files 2.3 Trajectory files 2.4 Memory scores 2.5 Saving the compiled dataset", " 2 Data Preparation 2.1 Setup Packages used for data preparation library(tidyverse) library(here) Functions writted for this analysis #function angleDiff() takes in 2 angles in degrees and gives out the difference between them (0-180) with the proper direction #(i.e. positive = clockwise, negative = counterclockwise; angle1 being theoretical 0/trueAngle) angleDiff &lt;- function(angle1, angle2){ x = angle2 - angle1 if (x &gt; 180) {x = x -360} else if (x &lt; -180) {x = x + 360} return(x) } #function dist() calculates distance between 2 given points (loc1, loc2) while taking in their X and Y separately dist &lt;- function(loc1X, loc1Y, loc2X, loc2Y) { d = sqrt(((loc1X-loc2X)**2)+((loc1Y-loc2Y)**2)) return(d) } #function angle() takes in 2 locations (a, b) and calculates angle between A-B and A-C (created inside the function) #a(X, Y) = character position, b(X, Y) = imaginary object position #necessary for relative influence calculation angle &lt;- function(a_X, a_Y, b_X, b_Y) { c_X = a_X c_Y = a_Y + 10 c = dist(a_X, a_Y, b_X, b_Y) b = dist(a_X, a_Y, c_X, c_Y) a = dist(b_X, b_Y, c_X, c_Y) cos_A = (b^2 + c^2 - a^2) / (2*b*c) angleRad = acos(cos_A) angle = (180 * angleRad) / pi if (a_X &gt; b_X) {angle = 360 - angle} return(angle) } Creating a list of subject IDs based on presence of summary files for Block 4 Subsequently, creating list of new random IDs which were used during a transfer of data between computers fn &lt;- list.files(path = here(&quot;data&quot;), pattern=&quot;*_feedbackPhase_block4_Sum&quot;) subjects &lt;- c() for (i_file in length(fn)) { subjects &lt;- substr(fn,1,4) } newID &lt;- sample(c(1000:9999), size=length(subjects), replace=FALSE) Retrieving participants’ age from participants.csv (used for participation tracking purposes, created manually) age &lt;- read.table(here(&quot;data&quot;, &quot;participants.csv&quot;), sep = &quot;;&quot;, header = TRUE, colClasses = &quot;character&quot;) %&gt;% select(study.ID, age, study) %&gt;% filter(study == &quot;yes&quot;) 2.2 Summary and Angle files The files are loaded in and joined into a big data frame containing all information from both summary and angle files for all participants Dataframes created along the way: - Sum_all: all participants - Sum: all data for 1 participant - sub_dat: data from 1 block for 1 participant blocks &lt;- c(1, 2, 3, 4) #number of blocks in the experiment Sum_all = tibble() #creating an empty tibble where eventually will the full dataset be stored for(i_sub in subjects){ #new, empty tibble for each participant Sum = tibble() for (i_block in blocks){ #loading in summary data fn &lt;- dir(path = here(&quot;data&quot;), pattern = sprintf(&quot;%s_feedbackPhase_block%s_Sum&quot;, i_sub, i_block), full.names = TRUE) sub_dat &lt;- as_tibble(read_delim(fn, delim = &quot;\\t&quot;, col_names = FALSE, col_types = &quot;dcdddddddddddddd&quot;)) %&gt;% rename(trial = X1, object = X2, sec2Beg = X3, landmarkX = X4, landmarkZ = X5, landmarkY = X6, objX = X7, objZ = X8, objY = X9, error=X13, secTrialRepl = X14, trialLen = X15, sec2End = X16, remLocX = X10, remLocY = X12, remLocZ = X11) %&gt;% mutate(ID=i_sub, newID=newID[which(subjects == i_sub)], age=age$age[which(i_sub==age$study.ID)], block=i_block, dropTime = (sec2Beg + secTrialRepl), miniblock = NA, objectTrial = NA, cue=NA, landmarkCuePosX=NA, landmarkCuePosY=NA, boundaryCuePosX=NA, boundaryCuePosY=NA, relativeInfluence=NA, correct_RI = NA, angleError=NA, landmarkAngle=NA, boundaryAngle=NA, relativeAngle=NA, correct_RA = NA, distanceTo1 = NA, distanceTo2=NA, distanceTo3=NA, averageDist=NA) #loading in angle data fn_A &lt;- dir(path = here(&quot;data&quot;), pattern = sprintf(&quot;%s_feedbackPhase_block%s_Angle&quot;, i_sub, i_block), full.names = TRUE) sub_dat_A &lt;- as_tibble(read_delim(fn_A, delim = &quot;\\t&quot;, col_names = FALSE, col_types = &quot;dcdddddddddd&quot;)) %&gt;% mutate(ID=i_sub, block=i_block) %&gt;% rename(trial = X1, object = X2, charX = X3, charZ = X4, charY = X5, estAngle = X6, objX = X7, objZ = X8, objY = X9, trueAngle = X10, secTrialEst = X11, sec2Est = X12) #joining together sub_dat and sub_datA sub_dat &lt;- inner_join(sub_dat, sub_dat_A, by=c(&quot;trial&quot;, &quot;object&quot;, &quot;objX&quot;, &quot;objZ&quot;, &quot;objY&quot;, &quot;ID&quot;, &quot;block&quot;)) #renaming objects in German to English sub_dat[sub_dat == &quot;die Lampe&quot;] &lt;- &quot;lamp&quot; sub_dat[sub_dat == &quot;die Blume&quot;] &lt;- &quot;flower&quot; sub_dat[sub_dat == &quot;der Partyhut&quot;] &lt;- &quot;partyhat&quot; sub_dat[sub_dat == &quot;das Monster&quot;] &lt;- &quot;monster&quot; #assigning miniblocks based on trial number for (i_trial in 1:(length(sub_dat$trial))){ if (sub_dat$trial[i_trial] &lt; 5) { sub_dat$miniblock[i_trial] &lt;- 1 } else if (sub_dat$trial[i_trial] &lt; 9) { sub_dat$miniblock[i_trial] &lt;- 2 } else if (sub_dat$trial[i_trial] &lt; 13) { sub_dat$miniblock[i_trial] &lt;- 3 } else { sub_dat$miniblock[i_trial] &lt;- 4 } #assigning objectTrial (1-16) - miniblock order number throughout the experiment sub_dat$objectTrial[i_trial] &lt;- (sub_dat$miniblock[i_trial]+((sub_dat$block[i_trial]-1)*4)) #finding distance between remembered position and other than target objects objects &lt;- c(&quot;monster&quot;, &quot;partyhat&quot;, &quot;lamp&quot;, &quot;flower&quot;) otherObjects &lt;- objects[objects != sub_dat$object[i_trial]] sub_dat$distanceTo1[i_trial] &lt;- dist(sub_dat$remLocX[i_trial], sub_dat$remLocY[i_trial], sub_dat$objX[sample(which(sub_dat$object == otherObjects[1]),1)], sub_dat$objY[sample(which(sub_dat$object == otherObjects[1]),1)]) sub_dat$distanceTo2[i_trial] &lt;- dist(sub_dat$remLocX[i_trial], sub_dat$remLocY[i_trial], sub_dat$objX[sample(which(sub_dat$object == otherObjects[2]),1)], sub_dat$objY[sample(which(sub_dat$object == otherObjects[2]),1)]) sub_dat$distanceTo3[i_trial] &lt;- dist(sub_dat$remLocX[i_trial], sub_dat$remLocY[i_trial], sub_dat$objX[sample(which(sub_dat$object == otherObjects[3]),1)], sub_dat$objY[sample(which(sub_dat$object == otherObjects[3]),1)]) #averaging the distance to the other 3 objects&#39; locations to get a single value sub_dat$averageDist[i_trial] &lt;- (sub_dat$distanceTo1[i_trial] + sub_dat$distanceTo2[i_trial] + sub_dat$distanceTo3[i_trial])/3 #calculating the angle error sub_dat$angleError[i_trial] &lt;- angleDiff(sub_dat$trueAngle[i_trial], sub_dat$estAngle[i_trial]) } Sum &lt;- bind_rows(sub_dat, Sum) } # JB: START ADAPTED SECTION # find names of boundary objects based on X-coordinate (should repeat for boundary) boundary_objects &lt;- Sum %&gt;% count(object, objX) %&gt;% # count appearances of each object at given location arrange(desc(n)) %&gt;% # sort based on count -&gt; boundary objects are always at same position -&gt; high counts slice(c(1,2)) %&gt;% # top two rows should be boundary objects pull(object) # extract boundary object names # find names of landmark objects based on Y-coordinate (should repeat for boundary) landmark_objects &lt;- Sum %&gt;% count(object, objY) %&gt;% # count appearances of each object at given location arrange(desc(n)) %&gt;% # sort based on count -&gt; boundary objects are always at same position -&gt; high counts tail(-2) %&gt;% # top two rows should be boundary objects, exclude them distinct(object) %&gt;% # store only unique object names pull(object) # extract boundary object names #assigning boundary- vs landmark-bound Sum &lt;- Sum %&gt;% mutate(cue = case_when( object %in% boundary_objects ~ &quot;boundary&quot;, object %in% landmark_objects ~ &quot;landmark&quot;) ) # some sanity checks if (length(landmark_objects) != 2){stop(sprintf(&quot;Did not find exactly 2 landmark objects for subject %s&quot;, i_sub))} if (length(boundary_objects) != 2){stop(sprintf(&quot;Did not find exactly 2 boundary objects for subject %s&quot;, i_sub))} if(any(is.na(Sum$cue))){stop(sprintf(&quot;Did not assign cue for at least one trial for subject %s&quot;, i_sub))} # Check that assignment of landmark or boundary produced the same cue value for each block -&gt; there should be 4 rows, one per object if (Sum %&gt;% count(object, cue) %&gt;% nrow() != 4){ warning(sprintf(&quot;Assignment of landmark/boundary cue has gone wrong for subject %s&quot;, i_sub)) } # JB: END ADAPTED SECTION #assigning predicted position based on the cue (boundary vs landmark) for (i_trial in 1:nrow(Sum)) { #block 1 if (Sum$block[i_trial] == 1){ #not applicable for block 1 as there has not been any movement of the landmark -&gt; all true locations and angles Sum$landmarkCuePosX[i_trial] &lt;- Sum$objX[i_trial] Sum$landmarkCuePosY[i_trial] &lt;- Sum$objY[i_trial] Sum$boundaryCuePosX[i_trial] &lt;- Sum$objX[i_trial] Sum$boundaryCuePosY[i_trial] &lt;- Sum$objY[i_trial] Sum$landmarkAngle[i_trial] &lt;- Sum$trueAngle[i_trial] Sum$boundaryAngle[i_trial] &lt;- Sum$trueAngle[i_trial] #block 2 }else if (Sum$block[i_trial] == 2){ #landmark-dependent objects if (Sum$cue[i_trial] == &quot;landmark&quot;) { #position predicted by landmark is the true object position Sum$landmarkCuePosX[i_trial] &lt;- Sum$objX[i_trial] Sum$landmarkCuePosY[i_trial] &lt;- Sum$objY[i_trial] #position predicted by boundary is the true object position in block 1 Sum$boundaryCuePosX[i_trial] &lt;- Sum$objX[sample(which(Sum$block == 1 &amp; Sum$object == Sum$object[i_trial]), 1)] Sum$boundaryCuePosY[i_trial] &lt;- Sum$objY[sample(which(Sum$block == 1 &amp; Sum$object == Sum$object[i_trial]), 1)] #angle predicted by landmark is angle towards the true location Sum$landmarkAngle[i_trial] &lt;- Sum$trueAngle[i_trial] #angle predicted by boundary is angle towards object position in block 1 Sum$boundaryAngle[i_trial] &lt;- angle(Sum$charX[i_trial], Sum$charY[i_trial], Sum$boundaryCuePosX[i_trial], Sum$boundaryCuePosY[i_trial]) #boundary-dependent objects } else { #position predicted by boundary is the true object position Sum$boundaryCuePosX[i_trial] &lt;- Sum$objX[i_trial] Sum$boundaryCuePosY[i_trial] &lt;- Sum$objY[i_trial] #position predicted by landmark is calculated based on landmark movement idx &lt;- which(Sum$objectTrial == 1 &amp; Sum$object == Sum$object[i_trial]) Sum$landmarkCuePosX[i_trial] &lt;- (Sum$objX[idx] + (Sum$landmarkX[i_trial]-Sum$landmarkX[idx])) Sum$landmarkCuePosY[i_trial] &lt;- (Sum$objY[idx] + (Sum$landmarkY[i_trial]-Sum$landmarkY[idx])) #angle predicted by boundary is angle towards the true location Sum$boundaryAngle[i_trial] &lt;- Sum$trueAngle[i_trial] #angle predicted by landmark is angle towards the position predicted by landmark Sum$landmarkAngle[i_trial] &lt;- angle(Sum$charX[i_trial], Sum$charY[i_trial] ,Sum$landmarkCuePosX[i_trial], Sum$landmarkCuePosY[i_trial]) } #block 3 and 4 }else{ #landmark-dependent objects if (Sum$cue[i_trial] == &quot;landmark&quot;) { # true position and angle Sum$landmarkCuePosX[i_trial] &lt;- Sum$objX[i_trial] Sum$landmarkCuePosY[i_trial] &lt;- Sum$objY[i_trial] Sum$landmarkAngle[i_trial] &lt;- Sum$trueAngle[i_trial] #Retrieving coordinates of the object in block 1 block1BoundaryX &lt;- Sum$objX[sample(which(Sum$block == 1 &amp; Sum$object == Sum$object[i_trial]), 1)] block1BoundaryY &lt;- Sum$objY[sample(which(Sum$block == 1 &amp; Sum$object == Sum$object[i_trial]), 1)] #Retrieving coordinates of the object in previous block block2BoundaryX &lt;- Sum$objX[sample(which(Sum$block == (Sum$block[i_trial]-1) &amp; Sum$object == Sum$object[i_trial]), 1)] block2BoundaryY &lt;- Sum$objY[sample(which(Sum$block == (Sum$block[i_trial]-1) &amp; Sum$object == Sum$object[i_trial]), 1)] #Calculating the distance to the remembered position of the 2 retrieved positions diffBlock1 &lt;- dist(block1BoundaryX, block1BoundaryY, Sum$remLocX[i_trial], Sum$remLocY[i_trial]) diffBlock2 &lt;- dist(block2BoundaryX, block2BoundaryY, Sum$remLocX[i_trial], Sum$remLocY[i_trial]) #The position that is closer to the remembered position is assigned as the position predicted by boundary if (diffBlock1 &lt; diffBlock2) { Sum$boundaryCuePosX[i_trial] &lt;- block1BoundaryX Sum$boundaryCuePosY[i_trial] &lt;- block1BoundaryY } else { Sum$boundaryCuePosX[i_trial] &lt;- block2BoundaryX Sum$boundaryCuePosY[i_trial] &lt;- block2BoundaryY } #Calculating the angle predicted by boundary based on the position predicted by boundary Sum$boundaryAngle[i_trial] &lt;- angle(Sum$charX[i_trial], Sum$charY[i_trial], Sum$boundaryCuePosX[i_trial], Sum$boundaryCuePosY[i_trial]) #boundary-dependent objects } else { #true position and angle Sum$boundaryCuePosX[i_trial] &lt;- Sum$objX[i_trial] Sum$boundaryCuePosY[i_trial] &lt;- Sum$objY[i_trial] Sum$boundaryAngle[i_trial] &lt;- Sum$trueAngle[i_trial] #Calculating landmark predicted position as if the object was landmark-dependent since block 1 idx1 &lt;- sample(which(Sum$block == 1 &amp; Sum$object == Sum$object[i_trial]), 1) block1LandmarkX &lt;- (Sum$objX[idx1] + (Sum$landmarkX[i_trial]-Sum$landmarkX[idx1])) block1LandmarkY &lt;- (Sum$objY[idx1] + (Sum$landmarkY[i_trial]-Sum$landmarkY[idx1])) #Calculating new position as if the object was landmark-dependent since previous block idx2 &lt;- sample(which(Sum$block == (Sum$block[i_trial]-1) &amp; Sum$object == Sum$object[i_trial]), 1) block2LandmarkX &lt;- (Sum$objX[idx2] + (Sum$landmarkX[i_trial]-Sum$landmarkX[idx2])) block2LandmarkY &lt;- (Sum$objY[idx2] + (Sum$landmarkY[i_trial]-Sum$landmarkY[idx2])) #Calculating the distance to the remembered position of the 2 calculated positions diffBlock1 &lt;- dist(block1LandmarkX, block1LandmarkY, Sum$remLocX[i_trial], Sum$remLocY[i_trial]) diffBlock2 &lt;- dist(block2LandmarkX, block2LandmarkY, Sum$remLocX[i_trial], Sum$remLocY[i_trial]) #The position that is closer to the remembered position is assigned as the position predicted by landmark if (diffBlock1 &lt; diffBlock2) { Sum$landmarkCuePosX[i_trial] &lt;- block1LandmarkX Sum$landmarkCuePosY[i_trial] &lt;- block1LandmarkY } else { Sum$landmarkCuePosX[i_trial] &lt;- block2LandmarkX Sum$landmarkCuePosY[i_trial] &lt;- block2LandmarkY } #Calculating the angle predicted by landmark based on the position predicted by landmark Sum$landmarkAngle[i_trial] &lt;- angle(Sum$charX[i_trial], Sum$charY[i_trial], Sum$landmarkCuePosX[i_trial], Sum$landmarkCuePosY[i_trial]) } } #calculating the relative influence of each cue on the remembered location of the cued object distL &lt;- dist(Sum$landmarkCuePosX[i_trial], Sum$landmarkCuePosY[i_trial], Sum$remLocX[i_trial], Sum$remLocY[i_trial]) distB &lt;- dist(Sum$boundaryCuePosX[i_trial], Sum$boundaryCuePosY[i_trial], Sum$remLocX[i_trial], Sum$remLocY[i_trial]) Sum$relativeInfluence[i_trial] &lt;- distL / (distL + distB) #calculating the relative influence of each cue on the indicated angle errorL &lt;- abs(angleDiff(Sum$landmarkAngle[i_trial], Sum$estAngle[i_trial])) errorB &lt;- abs(angleDiff(Sum$boundaryAngle[i_trial], Sum$estAngle[i_trial])) Sum$relativeAngle[i_trial] &lt;- errorL / (errorL + errorB) #calculating the relative influence with a new formula &quot;distCorrect/(distCorrect+distOther)&quot; and creating values in the same direction for both cues, new variable name - cue dissonance if (Sum$cue[i_trial] == &quot;boundary&quot;) { Sum$cueDissonance[i_trial] &lt;- distB / (distB + distL) Sum$cueDissonanceAngle[i_trial] &lt;- errorB / (errorL + errorB) } else { Sum$cueDissonance[i_trial] &lt;- distL / (distL + distB) Sum$cueDissonanceAngle[i_trial] &lt;- errorL / (errorL + errorB) } } Sum_all &lt;- bind_rows(Sum_all, Sum) #join the new participant data to the existing overall data frame } ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. ## Warning: Unknown or uninitialised column: `cueDissonance`. ## Warning: Unknown or uninitialised column: `cueDissonanceAngle`. Last changes to the dataframe to make it ready for analysis. #assigning the correct format to values in columns used for analysis Sum_all &lt;- Sum_all %&gt;% arrange(ID, objectTrial) %&gt;% #ordering the dataframe according to ID and the experiment sequence mutate( cueMM = recode(cue, &quot;boundary&quot; = 1, &quot;landmark&quot; = -1), #recoding cues to 1 and -1, used for mixed model analysis newID = as.factor(newID), cue = as.factor(cue), age = as.numeric(age) ) # calculating centered age and miniblock (using this more complicated way as opposed to directly do scale() because different subjects can have a different number of rows in the Sum_all tibble) Age_c &lt;- Sum_all %&gt;% group_by(ID) %&gt;% distinct(age) %&gt;% ungroup() %&gt;% mutate(age_c = scale(age, center=TRUE, scale=FALSE)) Mini_c &lt;- Sum_all %&gt;% group_by(ID) %&gt;% distinct(miniblock) %&gt;% ungroup() %&gt;% mutate(mini = scale(miniblock, center=TRUE, scale=FALSE)) Sum_all &lt;- inner_join(Sum_all, Age_c%&gt;%select(ID, age_c), by=&quot;ID&quot;) Sum_all &lt;- inner_join(Sum_all, Mini_c, by=c(&quot;ID&quot;, &quot;miniblock&quot;)) Assigning landmark-dependent/boundary-dependent object 1-2 (currently not used any further) Sum_all &lt;- mutate(Sum_all, cue1=NA) #creating new column for (i_trial in 1:nrow(Sum_all)) { #if this is the first time participant sees the object if (Sum_all$objectTrial[i_trial]==1) { #creates a dataframe &quot;this&quot; that has 2 lines (1 line = current object/trial + 1 line = other landmark-/boundary-dependent object) this &lt;- filter(Sum_all, ID == Sum_all$ID[i_trial] &amp; cue == Sum_all$cue[i_trial] &amp; objectTrial == 1) %&gt;% select(ID, objectTrial, cue, cue1) #if the first object has not been assigned number yet, then this object/trial is assigned 1, otherwise 2 if (is.na(this$cue1[1])) {Sum_all$cue1[i_trial] &lt;- 1} else {Sum_all$cue1[i_trial] &lt;- 2} #retrieves and assigns information about object number from objectTrial 1 } else { Sum_all$cue1[i_trial] &lt;- Sum_all$cue1[which(Sum_all$ID == Sum_all$ID[i_trial] &amp; Sum_all$object == Sum_all$object[i_trial] &amp; Sum_all$objectTrial == 1)] } } 2.3 Trajectory files Loading in Trajectory files and creating one huge data frame (~30,000 lines per participant) Traj = tibble() #creating an empty where eventually the full dataframe will be stored (&gt;2M lines) for(i_sub in subjects){ for (i_block in blocks){ #loading in a single trajectory file fn &lt;- dir(path = here(&quot;data&quot;), pattern = sprintf(&quot;%s_feedbackPhase_block%s_Traj&quot;, i_sub, i_block),full.names=TRUE) sub_dat &lt;- as_tibble(read_delim(fn, delim = &quot;\\t&quot;, col_names = FALSE, col_types = &quot;ddddddddddd&quot;)) %&gt;% mutate(ID=i_sub, newID = NA, block=i_block, miniblock = NA, object = NA, cue=NA) %&gt;% rename(trial=X1, sec2Frame=X2, charX=X3, charZ=X4, charY=X5, rotQua1=X6, rotQua2=X7, rotQua3=X8, rotQua4=X9, rotAngle=X10) %&gt;% relocate(ID, newID, block) #assigning miniblock for (i in 1:nrow(sub_dat)){ if (sub_dat$trial[i] &lt; 5) { sub_dat$miniblock[i] &lt;- 1 } else if (sub_dat$trial[i] &lt; 9) { sub_dat$miniblock[i] &lt;- 2 } else if (sub_dat$trial[i] &lt; 13) { sub_dat$miniblock[i] &lt;- 3 } else { sub_dat$miniblock[i] &lt;- 4 } #sub_dat$objectTrial[i] &lt;- (sub_dat$miniblock[i]+((sub_dat$block[i]-1)*4)) Currently not used so taken out for speed #retrieving information about object and cue from summary file obj &lt;- which(Sum_all$ID == sub_dat$ID[i] &amp; Sum_all$block == sub_dat$block[i] &amp; Sum_all$trial == sub_dat$trial[i]) #some trials in summary files missing therefore it leave the columns as NA is it cannot find the above index if (length(obj) == 1) { sub_dat$object[i] &lt;- Sum_all$object[obj] sub_dat$cue[i] &lt;- Sum_all$cue[obj] #sub_dat$cue1[i] &lt;- Sum_all$cue1[obj] currently not used } } #assigning newID sub_dat$newID &lt;- newID[which(subjects == i_sub)] # append to table with data from all subjects Traj &lt;- bind_rows(sub_dat, Traj) } } ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details ## Warning: One or more parsing issues, see `problems()` for details Getting rid of trajectory locations outside of the arena which have been probably caused by an internet glitch #removing locations outside of the arena (possibly internet glitch) Traj &lt;- filter(Traj, charX &gt; -27.5 &amp; charX &lt; 27.5 &amp; charY &gt; -27.5 &amp; charY &lt; 27.5) 2.4 Memory scores 2.4.1 Based on randomly distributed 1000 locations within the arena Generating 1000 randomly distributed locations within the arena thousand_x &lt;- c() thousand_y &lt;- c() points &lt;- c(1:1000) circle_r &lt;- 22.5 for (i in points){ # random angle alpha &lt;- 2 * pi * runif(1) # random radius r &lt;- circle_r * sqrt(runif(1)) # calculating coordinates x &lt;- r * cos(alpha) y &lt;- r * sin(alpha) thousand_x &lt;- c(thousand_x, x) thousand_y &lt;- c(thousand_y, y) } Calculating the memory score based on random distribution of 1000 locations within the arena Sum_all &lt;- Sum_all %&gt;% mutate(memoryScoreRand = NA, memoryScoreTraj = NA) #creating 2 new columns in the summary dataframe for (i_trial in 1:nrow(Sum_all)) { farther &lt;- 0 for (i_point in points) { #for each location distance to the true location of the cued object is calculated distance = dist(thousand_x[i_point], thousand_y[i_point], Sum_all$objX[i_trial], Sum_all$objY[i_trial]) #if the distance is bigger than the distance error then 1 is added to the count &quot;farther&quot; if (distance &gt; Sum_all$error[i_trial]) {farther &lt;- farther+1} else {farther &lt;- farther} } #final score is calculating the proportion of the 1000 locations that are farther from the true location than the remembered location Sum_all$memoryScoreRand[i_trial] &lt;- farther/1000 } 2.4.2 Based on 1000 locations taken from the participant’s trajectory Calculating memory scores based on 1000 points taken from the complete trajectory of the participant #basically row counter trials &lt;- 0 for (i_sub in subjects) { #selecting 1000 random locations from participant&#39;s overall trajectory XY &lt;- filter(Traj, ID == i_sub) %&gt;% select(ID, charX, charY) XY &lt;- XY[sample(nrow(XY), 1000), ] for (i_trial in 1:nrow(filter(Sum_all, ID == i_sub))) { farther &lt;- 0 for (i_point in 1:length(points)) { #for each location distance to the true location of the cued object is calculated distance = dist(XY$charX[i_point], XY$charY[i_point], Sum_all$objX[i_trial+trials], Sum_all$objY[i_trial+trials]) #if the distance is bigger than the distance error then 1 is added to the count &quot;farther&quot; if (distance &gt; Sum_all$error[i_trial+trials]) {farther &lt;- (farther+1)} } #final score is calculating the proportion of the 1000 locations that are farther from the true location than the remembered location Sum_all$memoryScoreTraj[i_trial+trials] &lt;- farther/1000 } trials &lt;- trials + nrow(filter(Sum_all, ID == i_sub)) } 2.5 Saving the compiled dataset Last changes before saving the datasets into big files Rearrange the columns into more cohesive order and replacing the local ID with a new ID that is necessary for data transfer. Sum_all &lt;- Sum_all %&gt;% relocate(newID, age, age_c, block, miniblock, mini, objectTrial, trial, cue, object, sec2Beg, dropTime, secTrialRepl, trialLen, sec2End, landmarkX, landmarkY, landmarkZ, objX, objY, objZ, remLocX, remLocY, remLocZ, error, distanceTo1, distanceTo2, distanceTo3, averageDist, memoryScoreRand, memoryScoreTraj, landmarkCuePosX, landmarkCuePosY, boundaryCuePosX, boundaryCuePosY, relativeInfluence, cueDissonance, trueAngle, estAngle, angleError) %&gt;% select(-ID) %&gt;% rename(ID = newID) Replacing local ID with a new ID that is necessary for data transfer, this time in Trajectory dataframe. Traj &lt;- Traj %&gt;% select(-ID) %&gt;% rename(ID = newID) Explanations of all columns: ID - randomly assigned ID of 4 digits age - 8-15 years old (entered as character atm) age_c - centered age block - 1-4 miniblock - 1-4 within block (in each miniblock each object appears once) mini - centered miniblocks objectTrial - 1-16, miniblocks throughout the experiment (in objectTrial 12, participants see a object for 12th time) trial - 1-16 within block cue - landmark vs boundary, randomly assigned in an input files cue1 - 1-2, to get rid of object names (landmark object 1, landmark object 2, boundary object 1, boundary object 2) - currently not generated object - “monster”, “partyhat”, “lamp”, “flower” sec2Beg - seconds from the beginning of the experiment to the beginning to the trial dropTime - seconds from the beginning of the experiment to the indication of remembered location of the cued object secTrialRepl - seconds from the beginning of the trial to the indication of remembered location of the cued object trialLen - trial length in seconds sec2End - seconds from the beginning of the experiment to the end of the trial landmarkX - position of landmark X coordinate landmarkY - position of landmark Y coordinate landmarkZ - position of landmark Z coordinate (not really used/useful) objX - position of the cued object of the trial X coordinate objY - position of the cued object of the trial Y coordinate objZ - position of the cued object of the trial Z coordinate (not really used/useful) remLocX - position participant indicated as the location of the cued object X coordinate remLocY - position participant indicated as the location of the cued object Y coordinate remLocZ - position participant indicated as the location of the cued object Z coordinate error - distance between the remembered location and the true location of the cued object distanceTo1 - distance between the remembered location and a wrong/uncued object 1 distanceTo2 - distance between the remembered location and a wrong/uncued object 2 distanceTo3 - distance between the remembered location and a wrong/uncued object 3 averageDist - average distance between the from remembered location and the other objects memoryScoreRand - memory score calculated based on randomly distributed 10,000 points memoryScoreTraj - memory score calculated based on randomly picked 10,000 points from the participant’s recorded path landmarkCuePosX - position of the cued object based on landmark (as if landmark-dependent) X coordinate, used for relative influence score landmarkCuePosY - position of the cued object based on landmark (as if landmark-dependent) Y coordinate, used for relative influence score boundaryCuePosX - position of the cued object based on boundary (as if boundary-dependent) X coordinate, used for relative influence score boundaryCuePosY - position of the cued object based on boundary (as if boundary-dependent) Y coordinate, used for relative influence score relativeInfluence - relative influence score (distance to landmark-dependent location / (distance to landmark-dependent location + distance to boundary-dependent location)) cueDissonance - distance to the correct location/ (distance to the correct location + distance to location predicted by the other cue) trueAngle - correct angle to the cued object from the current participant’s location estAngle - indicated angle to the cued object from the current participant’s location angleError - difference between trueAngle and estAngle landmarkAngle - angle to a object location predicted by landmark boundaryAngle - angle to a object location predicted by boundary relativeAngle - relative influence score of angle estimation (landmarkAngle/ (landmarkAngle+boundaryAngle)) cueDissonanceAngle - angle to the correct location/ (angle to the correct location + angle to location predicted by the other cue) charX - participant’s position when estimating the angle X coordinate charZ - participant’s position when estimating the angle Z coordinate charY - participant’s position when estimating the angle Y coordinate secTrialEst - seconds from the beginning of the trial to the angle estimation sec2Est - seconds from the beginning of the experiment to the angle estimation Saving these into text files into our local data folder. write.table(Sum_all, file = here(&quot;data&quot;, &quot;Sum.txt&quot;), sep = &quot; &quot;, row.names = FALSE, col.names = TRUE) write.table(Traj, file = here(&quot;data&quot;, &quot;Traj.txt&quot;), sep = &quot; &quot;, row.names = FALSE, col.names = TRUE) "],["analysis.html", "3 Analysis 3.1 Hypothesis 3.2 Set up 3.3 Descriptives 3.4 Block 1 Performance 3.5 Cue Differences 3.6 Miniblocks Learning 3.7 Age", " 3 Analysis 3.1 Hypothesis Hypothesis: Boundary-dependent object position memory will improve between 8 and 15 years of age, while landmark-dependent object memory will stay relatively constant. 3.2 Set up knitr::opts_chunk$set(echo = TRUE) Packages used for data analysis library(here) library(tidyverse) library(broom) library(lme4) library(effsize) library(scico) library(cowplot) library(gghalves) library(ggnewscale) library(ggeffects) library(ggsignif) library(patchwork) library(Cairo) Functions written for this analysis #function circleFun() generates locations of 100 points that are in shape of circle #used for mapping out the arena in graphs circleFun &lt;- function(center = c(0,0), r = 27.5, npoints = 100){ tt &lt;- seq(0,2*pi,length.out = npoints) xx &lt;- center[1] + r * cos(tt) yy &lt;- center[2] + r * sin(tt) return(data.frame(x = xx, y = yy)) } #function dist() calculates distance between given 2 points (loc1, loc2) while taking in their X and Y separately dist &lt;- function(loc1X, loc1Y, loc2X, loc2Y) { d = sqrt(((loc1X-loc2X)**2)+((loc1Y-loc2Y)**2)) return(d) } Following chunk checks whether a folder “figures” exists and potentially creates one if (dir.exists(here(&quot;figures&quot;))){dir.create(here(&quot;figures&quot;))} Reading in the two big files containing the full dataset Sum_all &lt;- read_delim(here(&quot;data&quot; ,&quot;Sum.txt&quot;), delim = &quot; &quot;, col_names = TRUE, col_types = &quot;fdddddddfcdddddddddddddddddddddddddddddddddddddddd&quot;) Traj &lt;- read_delim(here(&quot;data&quot; ,&quot;Traj.txt&quot;), delim = &quot; &quot;, col_names = TRUE, col_types = &quot;fddddddddddddcd&quot;) Creating a list of subject IDs from the full dataset #generating subject ID list subjects &lt;- unique(Sum_all$ID) 3.2.1 Timeout sessions Identifying and filtering timeout sessions which are encoded as distance error = -1 (an impossible value) #summary of timeout trials timeout &lt;- filter(Sum_all, error == -1) print(sprintf(&quot;# timeout trials: %s&quot;, nrow(timeout))) ## [1] &quot;# timeout trials: 25&quot; print(sprintf(&quot;# participants with timeout trials: %s&quot;, length(unique(timeout$ID)))) ## [1] &quot;# participants with timeout trials: 15&quot; print(sprintf(&quot;average # timeout trials per participant with timeout trials: %s&quot;, nrow(timeout)/length(unique(timeout$ID)))) ## [1] &quot;average # timeout trials per participant with timeout trials: 1.66666666666667&quot; print(sprintf(&quot;average # timeout trials per participant: %s&quot;, nrow(timeout)/length(subjects))) ## [1] &quot;average # timeout trials per participant: 0.657894736842105&quot; #filtering timeout trials as they do not include location estimation Sum_all &lt;- filter(Sum_all, error != -1) 3.2.2 Exclusion criteria Participants are excluded based on performance in block 1 which is quantified using memory scores. Explanation graph Graph below visualizes the calculation of memory score for a single trial. #data sorting i_sub = subjects[5] #randomly selection one participant XY &lt;- filter(Traj, ID == i_sub) %&gt;% select(ID, charX, charY) #filtering the full trajectory of the participant XY &lt;- XY[sample(nrow(XY), 1000), ] #selecting randomly 1000 frames from the participant&#39;s complete trajectory graph_sub &lt;- filter(Sum_all, ID == i_sub) #filtering the summary data of the participant XY &lt;- mutate(XY, distance = NA, outside = NA) #creating 2 new columsn for the trajectory data frame for (i_point in 1:1000){ #calculating the distance between the random trajectory location and the true location of the cued bject in the given trial dista = dist(XY$charX[i_point], XY$charY[i_point], graph_sub$objX[10], graph_sub$objY[10]) XY$distance[i_point] &lt;- dista #adding the distance value to the dataframe #evaluating whether the distance between the random location and the object is bigger or smaller than the distance error in the given trial if (dista &gt; graph_sub$error[10]) {XY$outside[i_point] &lt;- TRUE} else {XY$outside[i_point] &lt;- FALSE} } #final used data outside &lt;- filter(XY, outside == TRUE) #creating separate dataframe for locations that are further from the object than the distance error inside &lt;- filter(XY, outside == FALSE) #creating separate dataframe for locations that are closer to the object than the distance error littleCircle &lt;- circleFun(center=c(graph_sub$objX[10],graph_sub$objY[10] ), r=graph_sub$error[10]) #circle dividing closer/further locations circle &lt;- circleFun() #arena border visualization #graph mem_score &lt;- ggplot(circle, aes(x, y)) + geom_path() + geom_path(subset(Traj, ID %in% i_sub), mapping=aes(x=charX, y=charY), size=0.2, alpha=0.7, linetype = 1) + geom_point(data= outside, aes(x=charX, y=charY, color=&quot;Trajectory Locations Further&quot;), size=0.7, alpha=0.7) + geom_point(data=inside, aes(x=charX, y=charY, color=&quot;Trajectory Locations Closer&quot;), size=0.7) + geom_path(data=littleCircle, aes(x,y), color=&quot;#E58A50&quot;) + geom_point(data=graph_sub, aes(x=objX[10], y=objY[10], color=&quot;True Object Location&quot;), size = 2) + geom_point(data=graph_sub, aes(x=remLocX[10], y=remLocY[10], color=&quot;Remembered Object Location&quot;), size=2) + theme_cowplot() + theme(aspect.ratio=1, axis.title = element_text(size=10), axis.text = element_text(size=10), plot.title = element_text(size=12), plot.subtitle = element_text(size = 11)) + labs(title = &quot;Memory score calculation based on trajectory&quot;, subtitle = paste(&quot;Memory score:&quot;, graph_sub$memoryScoreTraj[10]), x= &#39;X (virtual meters)&#39;, y= &#39;Y (virtual meters)&#39;) + scale_color_manual(name = &quot; &quot;, values= c(&quot;True Object Location&quot; = &quot;#F8DF77&quot;, &quot;Remembered Object Location&quot; = &quot;#95413F&quot;, &quot;Trajectory Locations Closer&quot; = &quot;#E58750&quot;, &quot;Trajectory Locations Further&quot; = &quot;#191900&quot;)) ggsave(filename=&quot;memory_score_visual.pdf&quot;, plot=mem_score, units = &quot;cm&quot;, width = 15, height = 11, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;memory_score_visual.png&quot;, plot=mem_score, units = &quot;cm&quot;, width = 15, height = 11, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) mem_score To be included in the analysis, participant’s memory scores from block 1 need to be significantly greater than the chance level 0.5. exclusion &lt;- c() #creating empty list that will contain the subject IDs that will be excluded for (i_sub in subjects) { score &lt;- t.test(subset(Sum_all, ID==i_sub &amp; block==1)$memoryScoreTraj, mu=0.5, alternative = &quot;greater&quot;) %&gt;% tidy() #one-tailed t.test of block 1 memory scores against chance level 0.5 if (score$p.value &gt; 0.05) { exclusion &lt;- c(exclusion, i_sub) Sum_all &lt;- filter(Sum_all, ID != i_sub) } } print(sprintf(&quot;# participants excluded: %s&quot;, length(exclusion))) ## [1] &quot;# participants excluded: 2&quot; print(sprintf(&quot;new overall sample size: %s&quot;, length(subjects)-length(exclusion))) ## [1] &quot;new overall sample size: 36&quot; 3.3 Descriptives Age Distribution Graph below shows the age distribution of our participants. #summarising data to get a single line for each participant age &lt;- Sum_all %&gt;% group_by(ID, age) %&gt;% summarise(n = n(), .groups=&quot;drop&quot;) ggplot(age, aes(x=age)) + geom_bar(fill=scico(1, palette=&quot;acton&quot;, begin=0.8)) + theme_cowplot() + background_grid(major=&quot;y&quot;, minor=&quot;y&quot;) + scale_x_continuous(breaks = c(8,9,10,11,12,13,14,15)) + theme(legend.position = &quot;none&quot;) + labs(x=&quot;Age&quot;, y=&quot;Count&quot;, title=&quot;Distribution of age&quot;) Reaction Time Next, we looked into reaction time (seconds between angle estimation and location estimation). #average RT reaction_time_dat &lt;- Sum_all %&gt;% mutate(posResponse = secTrialRepl - secTrialEst) %&gt;% #calculating the seconds between angle estimation and location estimation group_by(ID, age) %&gt;% summarise(posiMemResponse = mean(posResponse), .groups=&quot;drop&quot;) #raincloud graph showing distribution of RT, 1 point per participant ggplot(reaction_time_dat, aes(x=0, y=posiMemResponse)) + geom_half_violin(aes(x=-0.05), fill=scico(1, palette = &quot;acton&quot;, begin = 0.45), alpha =0.5, color=NA) + geom_point(aes(x=0.105, color=age), position = position_jitter(width =0.05, height = 0), shape=16, size = 2) + scale_color_scico(palette = &quot;acton&quot;) + geom_boxplot(width = .08, outlier.shape = NA) + theme_cowplot() + ylab(&#39;RT&#39;) + xlab(&#39;&#39;) + ggtitle(&#39;Average reaction time for each participant across the entire experiment&#39;) + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), aspect.ratio =1, plot.title = element_text(face=&quot;italic&quot;, size=12)) #average RT and sd for the full dataset reaction_time &lt;- summarise(reaction_time_dat, mean = mean(posiMemResponse), sd=sd(posiMemResponse), min=min(posiMemResponse), max=max(posiMemResponse)) reaction_time ## # A tibble: 1 × 4 ## mean sd min max ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 7.70 3.29 3.66 18.9 print(sprintf(&quot;The average reaction time was %s seconds (sd = %s).&quot;, round(reaction_time$mean, 3), round(reaction_time$sd, 3))) ## [1] &quot;The average reaction time was 7.701 seconds (sd = 3.288).&quot; Trial Length We also calculated the average length of a single trial. #average trial length for the full dataset trial_length &lt;- Sum_all %&gt;% summarise(mean = mean(trialLen), sd = sd(trialLen), min = min(trialLen), max = max(trialLen)) trial_length ## # A tibble: 1 × 4 ## mean sd min max ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 27.5 12.0 9.82 144. print(sprintf(&quot;The average trial length was %s seconds (sd = %s).&quot;, round(trial_length$mean, 3), round(trial_length$sd, 3))) ## [1] &quot;The average trial length was 27.48 seconds (sd = 12.032).&quot; 3.4 Block 1 Performance This subsection of the analysis aims to answer whether the participants completed the basic task according to the instructions before any manipulation was introduced. 3.4.1 Recalled locations First, we wanted to visualize the recalled locations relative to the object location so we calculated a new “error location” as if the cued object was at coordinate 0,0 inside the arena and created a heat map. The boundary of the arena is drawn in white. #creating a smaller data frame for trials only in block 1 and calculating the new error coordinates (newX, newY) heatMapDat &lt;- Sum_all %&gt;% filter(block==1) %&gt;% select(ID, miniblock, objX, objY, remLocX, remLocY, cue, block) %&gt;% mutate(newX = remLocX-objX, newY = remLocY - objY) #graphing heat_map_B1 &lt;- ggplot(heatMapDat, aes(x=newX, y=newY)) + # creating a heat map stat_density_2d(aes(fill = ..density..), geom = &quot;raster&quot;, contour = FALSE, na.rm=TRUE) + # setting a color palette from scico package scale_fill_scico(palette = &#39;lajolla&#39;, begin=1, end=0, name = &quot;Density&quot;) + # adding individual error locations on top in white geom_point(alpha=0.2, color=&quot;white&quot;, size=0.05) + # adding the boundary of the arena (as a reference for distance) geom_path(data = circle, aes(x, y), color=&quot;grey&quot;) + # plotting the x and y axis on 0,0 to visualize the center of the arena geom_hline(yintercept = 0) + geom_vline(xintercept = 0) + #changing titles labs(x = &quot;Error on X (vm)&quot;, y = &quot;Error on Y (vm)&quot;, title=&quot;Centralised Distribution of Error&quot;) + # aesthetical changes theme_cowplot() + theme(aspect.ratio=1, plot.title = element_text(face=&quot;italic&quot;, size=12), legend.title = element_text(size=10), legend.text = element_text(size=10)) + # adjusting axis limits and breaks scale_x_continuous(limits = c(-33, 33), breaks = c(-30, -20, -10, 0, 10, 20, 30)) + scale_y_continuous(limits = c(-33, 33), breaks = c(-30, -20, -10, 0, 10, 20, 30)) #saving the graph as pdf and png ggsave(&quot;heatMap_block1.pdf&quot;, plot=heat_map_B1, units = &quot;cm&quot;, width = 10, height = 10, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;heatMap_block1.png&quot;, plot=heat_map_B1, units = &quot;cm&quot;, width = 10, height = 10, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) #show the graph heat_map_B1 3.4.2 Memory score #creating dataset that only contains data from block 1 and summarizing for each participant summaryBlock1 &lt;- Sum_all %&gt;% filter(block==1) %&gt;% group_by(ID, block) %&gt;% summarise(memoryScore = mean(memoryScoreTraj), distanceOther = mean(averageDist), distanceTrue = mean(error), .groups=&quot;drop&quot;) To tested whether the memory scores are above chance level 0.5, we ran one sample, one tail t-test. t.test(summaryBlock1$memoryScore, mu = 0.5, alternative=&quot;greater&quot;) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.812 26.1 7.53e-25 35 0.791 Inf One Sample t-test greater Raincloud graph below visualizes the distribution of average memory scores in block 1 (1 point per participant) mem_score_B1 &lt;- ggplot(summaryBlock1, aes(x=block, y= memoryScore)) + # violin plot geom_half_violin(aes(x=block-0.06), fill=scico(1, palette = &quot;lajolla&quot;, begin = 0.45), alpha =0.5, color=NA) + # single subject data points (1 per participant) with horizontal jitter geom_point(aes(x=block+0.08), position = position_jitter(width =0.01, height = 0), shape=16, size = 1) + # boxplot of distribution (median, 1st and 3rd quartile) geom_boxplot(width = .05, outlier.shape = NA) + # adding plot of mean and SEM stat_summary(fun = mean, geom = &quot;point&quot;, size=1, shape = 16, position = position_nudge(-.06), colour = &quot;black&quot;) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;, position = position_nudge(-.06), colour = &quot;black&quot;, width = 0, size = 0.5) + # adding horizontal line at chance level 0.5 with annotation geom_hline(yintercept = 0.5, linetype=2) + annotate(&quot;text&quot;, label=&quot;chance = 0.5&quot;, x=1.2, y=0.52, size=3) + # correcting labels labs(x = &#39;&#39;, y = &#39;Memory Score (0-1)&#39;, title = &#39;Memory score&#39;) + # aesthetical changes theme_cowplot() + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), aspect.ratio = 1, plot.title = element_text(face=&quot;italic&quot;, size=12)) #saving the graph as pdf and png ggsave(&quot;memory_score_B1.pdf&quot;, plot=mem_score_B1, units = &quot;cm&quot;, width = 10, height = 7, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;memory_score_B1.png&quot;, plot=mem_score_B1, units = &quot;cm&quot;, width = 10, height = 7, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) #show the graph mem_score_B1 Assembly of graphs for positional memory in block 1. # using patchwork package to combine 2 separate graphs memory_B1 &lt;- mem_score_B1 + heat_map_B1 &amp; theme(axis.text = element_text(size=10), axis.title = element_text(size=10), plot.title = element_text(size=12)) &amp; plot_annotation(title = &#39;Memory Performance in Block 1&#39;, theme = theme(plot.title = element_text(size = 12, face=&quot;bold&quot;))) # saving the compiled graphs as pdf and png ggsave(&quot;Block1_loc.pdf&quot;, plot=memory_B1, units = &quot;cm&quot;, width = 15.9, height = 10, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;Block1_loc.png&quot;, plot=memory_B1, units = &quot;cm&quot;, width = 15.9, height = 10, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) # show the compiled graphs memory_B1 3.4.3 Distance from remembered locations to other locations We wanted to check that participants tried to recall the location of the correct object and did not mistake it with other 3 objects on regular basis so we calculated the average distance from the recalled location to the other objects’ locations (distanceToOther1 + distanceToOther2 + distanceToOther3 / 3) and compared it to the distance error to the true location of the cued object. This calculation is visualized in a graph below for a single example trial. #filtering for only trials in 1 miniblock for simplicity graph_sub &lt;- graph_sub %&gt;% filter(objectTrial == 5) distance_other &lt;- ggplot(circle, aes(x, y)) + # creating arena boundary geom_path() + # true location of cued object geom_point(data=graph_sub, aes(x=objX[2], y=objY[2], color=&quot;True Object Location&quot;), size = 2.5) + # line visualizing the distance error (between recalled location and true location) geom_segment(data=graph_sub, aes(x=remLocX[2], y=remLocY[2], xend= objX[2], yend= objY[2], color=&quot;True Object Location&quot;), alpha=.5) + # location of other object 1 &amp; distance to the recalled location geom_point(data=graph_sub, aes(x=remLocX[1], y=remLocY[1], color=&quot;Other Object Location&quot;), size=2.5) + geom_segment(data=graph_sub, aes(x=remLocX[1], y=remLocY[1], xend= remLocX[2], yend= remLocY[2], color=&quot;Other Object Location&quot;), alpha=.5) + # location of other object 2 &amp; distance to the recalled location geom_point(data=graph_sub, aes(x=remLocX[3], y=remLocY[3], color=&quot;Other Object Location&quot;), size=2.5) + geom_segment(data=graph_sub, aes(x=remLocX[3], y=remLocY[3], xend= remLocX[2], yend= remLocY[2], color=&quot;Other Object Location&quot;), alpha=.5) + # location of other object 3 &amp; distance to the recalled location geom_point(data=graph_sub, aes(x=remLocX[4], y=remLocY[4], color=&quot;Other Object Location&quot;), size=2.5) + geom_segment(data=graph_sub, aes(x=remLocX[4], y=remLocY[4], xend= remLocX[2], yend= remLocY[2], color=&quot;Other Object Location&quot;), alpha=.5) + # recalled location of the cued object geom_point(data=graph_sub, aes(x=remLocX[2], y=remLocY[2], color=&quot;Remembered Object Location&quot;), size=2.5) + # aesthetical changes theme_cowplot() + theme(aspect.ratio=1, axis.title = element_text(size=10), axis.text = element_text(size=10), plot.title = element_text(size=12), plot.subtitle = element_text(size = 11)) + # changing labels and title labs(title = &quot;Distance from remembered location to other locations&quot;, subtitle = paste(sprintf(&quot;Distance Error: %s vm&quot;, graph_sub$error[2]), sprintf(&quot;Average Distance to Other Objects: %s vm&quot;, round(graph_sub$averageDist[2], 2)), sep=&quot;\\n&quot;), x= &#39;X (vm)&#39;, y= &#39;Y (vm)&#39;) + # specifying colors manually scale_color_manual(name = &quot; &quot;, values= c(&quot;True Object Location&quot; = &quot;#883E3A&quot;, &quot;Remembered Object Location&quot; = &quot;#E37D50&quot;, &quot;Other Object Location&quot; = &quot;#F6D868&quot;)) # saving graph as pdf and png ggsave(filename=&quot;distance_other_visual.pdf&quot;, plot=distance_other, units = &quot;cm&quot;, width = 15, height = 11, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;distance_other_visual.png&quot;, plot=distance_other, units = &quot;cm&quot;, width = 15, height = 11, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) # show the graph distance_other To test this, we ran paired t-test which showed that on average there is a difference between these 2 distances. t.test(summaryBlock1$distanceOther, summaryBlock1$distanceTrue, paired = TRUE) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 10.8 15.9 1.31e-17 35 9.43 12.2 Paired t-test two.sided Graph visualizing this comparison is below. #necessary pivoting of the dataset for the following graph summaryBlock1 &lt;- pivot_longer(summaryBlock1, cols=c(distanceTrue, distanceOther)) distance_B1 &lt;- ggplot(summaryBlock1, aes(x=name, y= value)) + # specifying axis limits and breaks scale_x_discrete(limits = c(&#39;distanceTrue&#39;, &#39;distanceOther&#39;), labels = c(&#39;to Correct Location&#39;, &#39;to Other Object Locations&#39;)) + scale_y_continuous(limits = c(0, 28), breaks = c(5, 10, 15, 20 , 25)) + # violin plot gghalves::geom_half_violin(data=summaryBlock1 %&gt;% filter(name==&quot;distanceOther&quot;), position=position_nudge(+0.2), aes(fill=name),alpha =0.7, color=NA, side=&quot;r&quot;) + gghalves::geom_half_violin(data=summaryBlock1 %&gt;% filter(name==&quot;distanceTrue&quot;), position=position_nudge(-0.2), aes(fill=name),alpha =0.7, color=NA, side=&quot;l&quot;) + # scico palette lajolla for violin plot fill scale_fill_scico_d(palette = &#39;lajolla&#39;, begin=0.2, end=0.75) + # single subject data points (1 per participant) geom_point(shape=16, size = 1) + # boxplot of distribution (median, 1st and 3rd quartile) geom_boxplot(data=summaryBlock1 %&gt;% filter(name==&quot;distanceOther&quot;), position=position_nudge(+0.1), width = .1, outlier.shape = NA) + geom_boxplot(data=summaryBlock1 %&gt;% filter(name==&quot;distanceTrue&quot;), position=position_nudge(-0.1), width = .1, outlier.shape = NA) + # adding plot of mean and SEM stat_summary(data=summaryBlock1 %&gt;% filter(name==&quot;distanceOther&quot;), position=position_nudge(+0.2), fun = mean, geom = &quot;point&quot;, size=1, shape = 16, colour = &quot;black&quot;) + stat_summary(data=summaryBlock1 %&gt;% filter(name==&quot;distanceOther&quot;), position=position_nudge(+0.2), fun.data = mean_se, geom = &quot;errorbar&quot;, colour = &quot;black&quot;, width = 0, size = 0.5) + stat_summary(data=summaryBlock1 %&gt;% filter(name==&quot;distanceTrue&quot;), position=position_nudge(-0.2), fun = mean, geom = &quot;point&quot;, size=1, shape = 16, colour = &quot;black&quot;) + stat_summary(data=summaryBlock1 %&gt;% filter(name==&quot;distanceTrue&quot;), position=position_nudge(-0.2), fun.data = mean_se, geom = &quot;errorbar&quot;, colour = &quot;black&quot;, width = 0, size = 0.5) + # line connecting individual participants&#39; values geom_line(aes(group=ID), alpha=0.5) + # changing title and labels labs(x = &quot; &quot;, y = &quot;Distance (vm)&quot;, subtitle = &quot;In Block 1&quot;, title = &quot;Distance from Remembered Location to Object Locations&quot;) + # aesthetical changes theme_cowplot() + theme(legend.position = &quot;none&quot;, plot.title = element_text(size=12, lineheight = 1.1), plot.subtitle = element_text(face = &quot;bold&quot;, lineheight = 1.1), aspect.ratio = 0.55, axis.title = element_text(size=12)) + # visualizing the significance of the t-test geom_signif(comparisons = list(c(&quot;distanceTrue&quot;, &quot;distanceOther&quot;)), test=&quot;t.test&quot;, test.args=list(alternative = &quot;two.sided&quot;, var.equal = FALSE, paired=TRUE), map_signif_level = TRUE, tip_length = 0, extend_line = 0.045, y_position = 26) # saving the graph as pdf and png ggsave(&quot;distances_B1.pdf&quot;, plot=distance_B1, units = &quot;cm&quot;, width = 13, height = 10, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;distances_B1.png&quot;, plot=distance_B1, units = &quot;cm&quot;, width = 13, height = 10, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) # show the graph distance_B1 3.5 Cue Differences Next we wanted to investigate whether the participants followed the cues in block 2-4 after landmark and landmark-dependent object movement. Also, is there performance difference between landmark- vs boundary-dependent objects? 3.5.1 Relative Influence Relative Influence has been used in the field for over a decade now, initially introduced in paper by Doeller, King and Burgess (2008). “For blocks 2–4, we attempted to quantify the relative influence of either cue on each response location. In a pilot study, we noticed that incorrect responses tended to be clustered around locations previously associated with the incorrect cue: either during block 1 or during the immediately preceding block. Accordingly, we calculated the relative influence of boundary versus landmark in blocks 2–4 as d L/(d L + d B), where d L is the distance of the response from the location predicted by the landmark and d B is the distance from the location predicted by the boundary. This measure varies between 0 (using the landmark) and 1 (using the boundary). On the basis of our pilot data the incorrect cue potentially predicts two different locations in blocks 3 and 4 (reflecting the object’s positions relative to it in the preceding block and in block 1): we used whichever was closest to the response location.” Explanation Graph Below, the calculation of relative influence score is visualised. #loading a data from block 2-4 for a single participant graph_sub &lt;- filter(Sum_all, ID == subjects[5] &amp; block == 4 &amp; trial==15) relativeInf_graph &lt;- ggplot(data=graph_sub) + # location predicted by landmark geom_point(aes(x=landmarkCuePosX, y=landmarkCuePosY, color=&quot;Location Predicted by Landmark&quot;), size = 2.5) + # line visualizing the distance error (between recalled location and landmark-predicted location) geom_segment(aes(x=remLocX, y=remLocY, xend= landmarkCuePosX, yend=landmarkCuePosY, color=&quot;Location Predicted by Landmark&quot;), alpha=.5) + # adding dL label annotate(&quot;text&quot;, label=&quot;dL&quot;, x=-7.8, y=-9.5, size=4, color=&quot;#C6F1B1&quot;, fontface =2) + # location predicted by boundary geom_point(aes(x=boundaryCuePosX, y=boundaryCuePosY, color=&quot;Location Predicted by Boundary&quot;), size = 2.5) + # line visualizing the distance error (between recalled location and true location) geom_segment(aes(x=boundaryCuePosX, y=boundaryCuePosY, xend= remLocX, yend= remLocY, color=&quot;Location Predicted by Boundary&quot;), alpha=.5) + # adding dB label annotate(&quot;text&quot;, label=&quot;dB&quot;, x=10, y=3, size=4, color=&quot;#592758&quot;, fontface =2) + #recalled location geom_point(aes(x=remLocX, y=remLocY, color = &quot;Remembered Object Location&quot;), size = 2.5) + #landmark location geom_point(aes(x=landmarkX, y=landmarkY), shape = 15, color = &quot;#94A98F&quot;, size=3) + annotate(&quot;text&quot;, label=&quot;Landmark&quot;, x= -16, y = -3.5, size=3.5, color= &quot;#94A98F&quot;) + # creating arena boundary geom_path(data=circle, aes(x, y)) + # aesthetical changes theme_cowplot() + theme(aspect.ratio=1, axis.title = element_text(size=10), axis.text = element_text(size=10), plot.title = element_text(size=12), plot.subtitle = element_text(size = 11)) + # changing labels and title labs(title = &quot;Relative Influence Calculation&quot;, subtitle = paste(&quot;dL / (dL + dB) &quot;, sprintf(&quot;Relative Influence: %s &quot;, round(graph_sub$relativeInfluence, 2)), sep=&quot;\\n&quot;), x= &#39;X (vm)&#39;, y= &#39;Y (vm)&#39;) + # specifying colors manually scale_color_manual(name = &quot; &quot;, values= c(&quot;Location Predicted by Boundary&quot; = &quot;#592758&quot;, &quot;Location Predicted by Landmark&quot; = &quot;#C6F1B1&quot;, &quot;Remembered Object Location&quot; = &quot;red&quot;)) # saving graph as pdf and png ggsave(filename=&quot;relative_influence_visual.pdf&quot;, plot=relativeInf_graph, units = &quot;cm&quot;, width = 15, height = 11, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;relative_influence_visual.png&quot;, plot=relativeInf_graph, units = &quot;cm&quot;, width = 15, height = 11, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) # show the graph relativeInf_graph First, let’s create a subset dataframe that has data only from block 2-4 and get rid of us currently unnecessary columns. Then we summarize relative influence score, correct cue influence and distance error. subset_RI &lt;- Sum_all %&gt;% filter(block!=1) %&gt;% select(-object, -sec2Beg, -sec2Est, -dropTime, -sec2End, -trialLen, -secTrialEst) relativeInfluenceBlocks &lt;- subset_RI %&gt;% group_by(ID, cue) %&gt;% summarise(relativeInf = mean(relativeInfluence), cueDis = mean(cueDissonance), distanceError = mean(error), age=unique(age), .groups=&quot;drop&quot;) T-Tests As score 0.5 points towards location between the location predicted by landmark and location predicted by boundary, we ran a one sample, one tail t-test to test whether the relative scores for landmark-dependent objects are less than 0.5. t.test(subset(relativeInfluenceBlocks, cue==&quot;landmark&quot;)$relativeInf, mu = 0.5, alternative = &quot;less&quot;) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.384 -8.20 5.76e-10 35 -Inf 0.408 One Sample t-test less After we ran a one sample, one tail t-test to test whether the relative scores for boundary-dependent objects are higher than 0.5. t.test(subset(relativeInfluenceBlocks, cue==&quot;boundary&quot;)$relativeInf, mu = 0.5, alternative = &quot;greater&quot;) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.638 10.2 2.41e-12 35 0.615 Inf One Sample t-test greater We also tested these two groups against each other to see if the scores are significantly different. t.test(subset(relativeInfluenceBlocks, cue==&quot;boundary&quot;)$relativeInf, subset(relativeInfluenceBlocks, cue==&quot;landmark&quot;)$relativeInf, paired=TRUE) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.254 10.7 1.57e-12 35 0.206 0.302 Paired t-test two.sided Graph This difference in relative influence scores between boundary-dependent objects and landmark-dependent objects is visualized in a graph below. rel_Inf &lt;- ggplot(relativeInfluenceBlocks, aes(x=cue, y=relativeInf)) + # changing labels and titles scale_x_discrete(labels = c(&#39;Boundary&#39;, &#39;Landmark&#39;)) + labs(x = &quot; &quot;, y = &quot;Relative Influence (0-1)&quot;, title = &quot;Positional Memory&quot;) + # violin plots gghalves::geom_half_violin(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.2), aes(fill=cue),alpha =0.7, color=NA, side=&quot;r&quot;) + gghalves::geom_half_violin(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.2), aes(fill=cue),alpha =0.7, color=NA, side=&quot;l&quot;) + # scico palette tokyo scale_fill_scico_d(palette = &#39;tokyo&#39;, begin=0.15, end=0.85) + # single subject data points (1 per participant) geom_point(shape=16, size = 1) + # line connecting individual participants&#39; values geom_line(aes(group=ID), alpha=0.5) + # boxplot of distribution (median, 1st and 3rd quartile) geom_boxplot(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.1), width = .1, outlier.shape = NA) + geom_boxplot(data= relativeInfluenceBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.1), width = .1, outlier.shape = NA) + # adding plot of mean and SEM stat_summary(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.2), fun = mean, geom = &quot;point&quot;, size=1, shape = 16, colour = &quot;black&quot;) + stat_summary(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.2), fun.data = mean_se, geom = &quot;errorbar&quot;, colour = &quot;black&quot;, width = 0, size = 0.5) + stat_summary(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.2), fun = mean, geom = &quot;point&quot;, size=1, shape = 16, colour = &quot;black&quot;) + stat_summary(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.2), fun.data = mean_se, geom = &quot;errorbar&quot;, colour = &quot;black&quot;, width = 0, size = 0.5) + # aesthetical changes theme_cowplot() + theme(legend.position = &quot;none&quot;, plot.title = element_text(size=12, lineheight = 1.1), axis.title = element_text(size=10)) + # visualizing the significance level of the t-test geom_signif(comparisons = list(c(&quot;landmark&quot;, &quot;boundary&quot;)), test=&quot;t.test&quot;, test.args=list(alternative = &quot;two.sided&quot;, paired=TRUE), map_signif_level = TRUE, tip_length = 0, extend_line = 0.045, y_position = 0.85) + # adding line at 0.5 (not-following either cue) geom_hline(yintercept=0.5, linetype=2, alpha=0.6) + # changing limits and breaks of y-axis scale_y_continuous(limits=c(0.1, 0.9), breaks = c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)) + # adding annotation of significance level of individual t-tests annotate(&quot;text&quot;, label=&quot;***&quot;, size=3, y=0.8, x=0.9, fontface =2) + annotate(&quot;text&quot;, label=&quot;***&quot;, size=3, y=0.15, x=2.1, fontface =2) # saving graphs as pdf and png ggsave(&quot;relativeInfluence.pdf&quot;, plot=rel_Inf, units = &quot;cm&quot;, width = 15, height = 11, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;relativeInfluence.png&quot;, plot=rel_Inf, units = &quot;cm&quot;, width = 15, height = 11, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) # show the graph rel_Inf Mixed Models As a first step towards building a full mixed effects model, we tested a simpliest version with only cue as a fixed effect and a random slope and random intercepts for participants. We did not use cue as a factor but in a recoded version of landmark = -1 and boundary = 1. formulaCue &lt;- &quot;relativeInfluence ~ cueMM + (1+cueMM|ID)&quot; modelCue &lt;- lme4::lmer(formula = formulaCue, data=subset_RI) summary(modelCue) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeInfluence ~ cueMM + (1 + cueMM | ID) ## Data: subset_RI ## ## REML criterion at convergence: -512.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.9647 -0.7254 -0.0185 0.6896 3.2229 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.0009096 0.03016 ## cueMM 0.0042558 0.06524 -0.09 ## Residual 0.0406835 0.20170 ## Number of obs: 1691, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.510803 0.007026 72.70 ## cueMM 0.127014 0.011931 10.65 ## ## Correlation of Fixed Effects: ## (Intr) ## cueMM -0.055 To test, whether cue is a significant predictor we ran a likelihood ratio test comparing our simpliest model and a model containing only random effects. formulaCueControl&lt;- &quot;relativeInfluence ~ 1 + (1+cueMM|ID)&quot; modelCueControl &lt;- lme4::lmer(formula = formulaCueControl, data=subset_RI) ratioCue &lt;- anova(modelCue, modelCueControl) ## refitting model(s) with ML (instead of REML) ratioCue ## Data: subset_RI ## Models: ## modelCueControl: relativeInfluence ~ 1 + (1 + cueMM | ID) ## modelCue: relativeInfluence ~ cueMM + (1 + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelCueControl 5 -466.00 -438.84 238 -476.00 ## modelCue 6 -515.99 -483.39 264 -527.99 51.989 1 5.581e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 3.5.2 Distance Error Differences Previously, Julian et al (2019) showed that there is a difference in distance error between boundary-dependent and landmark-dependent objects so we ran a paired t-test to replicate these findings in this new participant demographic. t.test(subset(relativeInfluenceBlocks, cue==&quot;boundary&quot;)$distanceError, subset(relativeInfluenceBlocks, cue==&quot;landmark&quot;)$distanceError, paired=TRUE) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.708 1.61 0.117 35 -0.186 1.60 Paired t-test two.sided We did not replicate these findings and the lack of difference is evident in the graph below. cue_Dist &lt;- ggplot(relativeInfluenceBlocks, aes(x=cue, y= distanceError)) + # changing labels and title scale_x_discrete(labels = c(&#39;Boundary&#39;, &#39;Landmark&#39;)) + labs(x = &quot; &quot;, y = &quot;Distance Error (vm)&quot;, title = &quot;Positional Memory&quot;) + # violin plot gghalves::geom_half_violin(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.2), aes(fill=cue),alpha =0.7, color=NA, side=&quot;r&quot;) + gghalves::geom_half_violin(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.2), aes(fill=cue),alpha =0.7, color=NA, side=&quot;l&quot;) + # scico palette tokyo scale_fill_scico_d(palette = &#39;tokyo&#39;, begin=0.15, end=0.85) + # single subject data points (1 per participant) geom_point(shape=16, size = 1) + # line connecting individual participants&#39; values geom_line(aes(group=ID), alpha=0.5) + # boxplot of distribution (median, 1st and 3rd quartile) geom_boxplot(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.1), width = .1, outlier.shape = NA) + geom_boxplot(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.1), width = .1, outlier.shape = NA) + # adding plot of mean and SEM stat_summary(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.2), fun = mean, geom = &quot;point&quot;, size=1, shape = 16, colour = &quot;black&quot;) + stat_summary(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.2), fun.data = mean_se, geom = &quot;errorbar&quot;, colour = &quot;black&quot;, width = 0, size = 0.5) + stat_summary(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.2), fun = mean, geom = &quot;point&quot;, size=1, shape = 16, colour = &quot;black&quot;) + stat_summary(data=relativeInfluenceBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.2), fun.data = mean_se, geom = &quot;errorbar&quot;, colour = &quot;black&quot;, width = 0, size = 0.5) + # aesthetical changes theme_cowplot() + theme(legend.position = &quot;none&quot;, plot.title = element_text(size=12, lineheight = 1.1), aspect.ratio = 0.55, axis.title = element_text(size=12)) + # visualizing the significance level of the t-test geom_signif(comparisons = list(c(&quot;landmark&quot;, &quot;boundary&quot;)), test=&quot;t.test&quot;, test.args=list(alternative = &quot;two.sided&quot;, paired=TRUE), map_signif_level = TRUE, tip_length = 0, extend_line = 0.045, y_position = 26) # saving the graph as pdf and png ggsave(&quot;distancesError.pdf&quot;, plot=cue_Dist, units = &quot;cm&quot;, width = 15, height = 11, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;distancesError.png&quot;, plot=cue_Dist, units = &quot;cm&quot;, width = 15, height = 11, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) # show the plot cue_Dist 3.6 Miniblocks Learning 3.6.1 Graphs The graph below shows the relative influence scores averaged for each miniblock in block 2-4 (averaging over 6 scores for each miniblock) # necessary summarizing for the graph below summary_miniblock &lt;- subset_RI %&gt;% group_by(ID, miniblock, cue) %&gt;% summarise(relativeInf = mean(relativeInfluence), riSD = sd(relativeInfluence), .groups = &quot;drop&quot;) g_mini &lt;- ggplot(summary_miniblock, aes(miniblock, relativeInf, group=interaction(cue, ID), color=cue)) + # connects the mean values for each participant geom_line(size=0.8, alpha = 0.3) + # overall mean and se stat_summary(fun=mean, aes(group=cue), geom=&quot;point&quot;, size=2) + stat_summary(fun.data=mean_se, aes(group=cue), geom=&quot;errorbar&quot;, size=0.8, width=0.1, alpha=0.95) + # connects the overall mean to show the improvement stat_summary(fun=mean, aes(group=cue), geom=&quot;line&quot;, size = 1.5) + # line showing 0.5 neutral relative score for reference geom_hline(yintercept = 0.5, linetype = 2) + # changing labels and titles labs(x= &quot;Miniblock&quot;, y = &quot;Relative Influence (0-1)&quot;, title = &quot;Averaged across Blocks&quot;, color = &quot;Cue&quot;) + # aesthitical changes theme_cowplot() + # assigning scico palette tokyo as a color palatte scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + # changing limits and breaks on both axis scale_y_continuous(limits = c(0,1), breaks = c(0, 0.25, 0.5, 0.75, 1)) + scale_x_continuous(limits = c(0.5, 4.5), breaks = c(1,2,3,4)) #show the graph g_mini The graph below shows the relative influence scores for each miniblock throughout block 2-4 (averaging only over 2 scores per miniblock) #necessary summarizing for the graph below summary_objectTrial &lt;- subset_RI %&gt;% group_by(ID, objectTrial, cue) %&gt;% summarise(relativeInf = mean(relativeInfluence), riSD = sd(relativeInfluence), .groups = &quot;drop&quot;) g_objTrial &lt;- ggplot(summary_objectTrial, aes(objectTrial, relativeInf, group=interaction(cue, ID), color=cue)) + # connects the mean values for each participant within each block geom_line(data= subset(summary_objectTrial, objectTrial &lt; 9), size=0.8, alpha = 0.3) + geom_line(data= subset(summary_objectTrial, objectTrial &lt; 13 &amp; objectTrial &gt; 8), size=0.8, alpha = 0.3) + geom_line(data= subset(summary_objectTrial, objectTrial &gt; 12), size=0.8, alpha = 0.3) + # overall mean and se stat_summary(fun=mean, aes(group=cue), geom=&quot;point&quot;, size=2) + stat_summary(fun.data=mean_se, aes(group=cue), geom=&quot;errorbar&quot;, size=0.8, width=0.1, alpha=0.95, position = position_nudge(x=0.01)) + # line connecting the average values within each block stat_summary(data = subset(summary_objectTrial, objectTrial &lt; 9), fun=mean, aes(group=cue), geom=&quot;line&quot;, size = 1.5) + stat_summary(data = subset(summary_objectTrial, objectTrial &lt; 13 &amp; objectTrial &gt; 8), fun=mean, aes(group=cue), geom=&quot;line&quot;, size = 1.5) + stat_summary(data = subset(summary_objectTrial, objectTrial &gt; 12), fun=mean, aes(group=cue), geom=&quot;line&quot;, size = 1.5) + # assigning scico palette tokyo as a color palatte scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + # line showing 0.5 neutral relative score for reference geom_hline(yintercept = 0.5, linetype = 2) + # adding a vertical lines showing the start of a new block with a proper label geom_vline(xintercept = 4.9, alpha = 0.7, linetype=3) + annotate(&quot;text&quot;, label = &quot;Block 2&quot;, x = 5.6, y = 1, size = 4) + geom_vline(xintercept = 8.9, alpha = 0.7, linetype=3) + annotate(&quot;text&quot;, label = &quot;Block 3&quot;, x = 9.6, y = 1, size = 4) + geom_vline(xintercept = 12.9, alpha = 0.7, linetype=3) + annotate(&quot;text&quot;, label = &quot;Block 4&quot;, x = 13.6, y = 1, size = 4) + # changing labels and titles labs(x= &quot;Miniblock&quot;, y = &quot;Relative Influence (0-1)&quot;, title= &quot;Separately per Block&quot;, color= &quot;Cue&quot;) + # changing limits and breaks and its labels of both axis scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1), limits = c(0,1)) + scale_x_continuous(breaks = c(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16), labels = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;)) + # aesthetical changes theme_cowplot() #show the graph g_objTrial The two graphs created above are composed into a single layout for better, more wholesome visualisation. # specifying the layout layout &lt;- &quot; AAAAAA AAAAAA AAAAAA BB#### BB#C## BB#### &quot; # assigning a variable for legend g_leg &lt;- guide_area() g_min &lt;- g_objTrial + g_mini + g_leg + # indicating the layout and gathering the legends plot_layout(design = layout, guides = &quot;collect&quot;) &amp; # unifying aesthetical aspects, mainly text size and style theme(axis.title = element_text(size = 10), axis.text = element_text(size=10), legend.title = element_text(size=10), legend.text = element_text(size=10), plot.title = element_text(size=12, face=&quot;italic&quot;), plot.tag = element_text(size = 10, face=&quot;bold&quot;)) &amp; # adding title and tags plot_annotation(title = &#39;Positional Memory&#39;, theme = theme(plot.title = element_text(size = 12, face=&quot;bold&quot;)), tag_levels = list(c(&#39;A&#39;, &#39;B&#39;))) # savvign the assembly as pd and png ggsave(&quot;relativeInfluence_min.pdf&quot;, plot=g_min, units = &quot;cm&quot;, width = 15.9, height = 13, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;relativeInfluence_min.png&quot;, plot=g_min, units = &quot;cm&quot;, width = 15.9, height = 13, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) # show the assembled graphs g_min 3.6.2 Miniblock 1 We noticed that there is a tendency for relative influence score to be above regardless cue-dependency so we wanted to test this statistically so we ran a one-sided, one sample t-test against 0.5. # summarizing by ID for all miniblocks 1 (in block 2-4) sub_mini_1 &lt;- subset_RI %&gt;% filter(miniblock == 1) %&gt;% group_by(ID) %&gt;% summarise(relInfluence = mean(relativeInfluence), .groups =&quot;drop&quot;) # one-tailed, one sample t-test t.test(sub_mini_1$relInfluence, mu=0.5, alternative = &quot;greater&quot;) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.577 6.12 0.000000269 35 0.555 Inf One Sample t-test greater As it seems the relative influence in miniblock is indeed higher than 0.5, therefore they are more likely following boundary as a cue (its old location). Next, we wanted to ensure that there is indeed no difference between the relative influence score between landmark-dependent and boundary-dependent objects in miniblock 1. # summarizing by ID and cue for all miniblocks 1 (in blocks 2-4) sub_mini_cue &lt;- subset_RI %&gt;% filter(miniblock == 1) %&gt;% group_by(ID, cue) %&gt;% summarise(relInfluence = mean(relativeInfluence), .groups =&quot;drop&quot;) # two-tailed, paired sample t-test t.test(subset(sub_mini_cue, cue==&quot;landmark&quot;)$relInfluence, subset(sub_mini_cue, cue==&quot;boundary&quot;)$relInfluence, paired=TRUE) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 -0.0131 -0.483 0.632 35 -0.0681 0.0419 Paired t-test two.sided 3.6.3 Mixed Models Relative Influence To test the learning throughout a block, we ran mixed effect model with interaction between cue and miniblock (centered) and added interaction between cue and miniblock as a random slope. formulaMiniblocksCue &lt;- &quot;relativeInfluence ~ cueMM*mini + (1+mini:cueMM|ID)&quot; modelMiniblocksCue &lt;- lme4::lmer(formula = formulaMiniblocksCue, data=subset_RI) summary(modelMiniblocksCue) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeInfluence ~ cueMM * mini + (1 + mini:cueMM | ID) ## Data: subset_RI ## ## REML criterion at convergence: -599.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.05149 -0.70240 -0.00336 0.72515 3.14230 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.0009218 0.03036 ## mini:cueMM 0.0002904 0.01704 0.08 ## Residual 0.0393939 0.19848 ## Number of obs: 1691, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.511043 0.006996 73.05 ## cueMM 0.127338 0.004828 26.38 ## mini -0.026550 0.004317 -6.15 ## cueMM:mini 0.058000 0.005169 11.22 ## ## Correlation of Fixed Effects: ## (Intr) cueMM mini ## cueMM 0.005 ## mini 0.000 -0.004 ## cueMM:mini 0.029 0.000 0.006 To test the significance of the interaction, we ran a likelihood ratio test comparing our model and a model with both cue and miniblock as predictors but without the interaction. #control model for interaction formulaMiniblocksControl &lt;- &quot;relativeInfluence ~ cueMM+mini + (1+mini:cueMM|ID)&quot; modelMiniblocksControl &lt;- lme4::lmer(formula = formulaMiniblocksControl, data=subset_RI) #likelihood ratio test ratioMini &lt;- anova(modelMiniblocksCue, modelMiniblocksControl) ## refitting model(s) with ML (instead of REML) ratioMini ## Data: subset_RI ## Models: ## modelMiniblocksControl: relativeInfluence ~ cueMM + mini + (1 + mini:cueMM | ID) ## modelMiniblocksCue: relativeInfluence ~ cueMM * mini + (1 + mini:cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelMiniblocksControl 7 -565.96 -527.92 289.98 -579.96 ## modelMiniblocksCue 8 -618.52 -575.06 317.26 -634.52 54.565 1 1.504e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Cue specific analysis To check whether miniblocks are a significant predictor without the cue we ran a model and likelihood ratio test separately for landmark-dependent and boundary-dependent objects. #landmark-dependent objects formulaMiniblocks &lt;- &quot;relativeInfluence ~ mini + (1+mini|ID)&quot; modelMiniblocksLandmark &lt;- lme4::lmer(formula = formulaMiniblocks, data=subset(subset_RI, cue==&quot;landmark&quot;)) summary(modelMiniblocksLandmark) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeInfluence ~ mini + (1 + mini | ID) ## Data: subset(subset_RI, cue == &quot;landmark&quot;) ## ## REML criterion at convergence: -297.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.2811 -0.6853 -0.1458 0.6247 2.9886 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.0055453 0.07447 ## mini 0.0004834 0.02199 0.27 ## Residual 0.0376717 0.19409 ## Number of obs: 851, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.383417 0.014087 27.22 ## mini -0.084418 0.006989 -12.08 ## ## Correlation of Fixed Effects: ## (Intr) ## mini 0.128 #control model formulaMiniControl &lt;- &quot;relativeInfluence ~ 1 + (1+mini|ID)&quot; modelMiniLandmarkControl &lt;- lme4::lmer(formula = formulaMiniControl, data=subset(subset_RI, cue==&quot;landmark&quot;)) #likelihood ratio test ratioMiniLandmark = anova(modelMiniblocksLandmark, modelMiniLandmarkControl) ## refitting model(s) with ML (instead of REML) ratioMiniLandmark ## Data: subset(subset_RI, cue == &quot;landmark&quot;) ## Models: ## modelMiniLandmarkControl: relativeInfluence ~ 1 + (1 + mini | ID) ## modelMiniblocksLandmark: relativeInfluence ~ mini + (1 + mini | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelMiniLandmarkControl 5 -243.44 -219.71 126.72 -253.44 ## modelMiniblocksLandmark 6 -300.36 -271.88 156.18 -312.36 58.922 1 1.64e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # boundary-dependent objects formulaMiniblocks &lt;- &quot;relativeInfluence ~ mini + (1+mini|ID)&quot; modelMiniblocksBoundary &lt;- lme4::lmer(formula = formulaMiniblocks, data=subset(subset_RI,cue==&quot;boundary&quot;)) summary(modelMiniblocksBoundary) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeInfluence ~ mini + (1 + mini | ID) ## Data: subset(subset_RI, cue == &quot;boundary&quot;) ## ## REML criterion at convergence: -427.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.1436 -0.5585 0.1068 0.7132 2.3100 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.0052596 0.07252 ## mini 0.0001497 0.01224 -0.46 ## Residual 0.0322649 0.17962 ## Number of obs: 840, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.637662 0.013588 46.928 ## mini 0.032131 0.005911 5.436 ## ## Correlation of Fixed Effects: ## (Intr) ## mini -0.142 #control model formulaMiniControl &lt;- &quot;relativeAngle ~ 1 + (1+mini|ID)&quot; modelMiniBoundaryControl &lt;- lme4::lmer(formula = formulaMiniControl, data=subset(subset_RI, cue==&quot;boundary&quot;)) #likelihood ratio test ratioMiniBoundary = anova(modelMiniblocksBoundary, modelMiniBoundaryControl) ## refitting model(s) with ML (instead of REML) ratioMiniBoundary ## Data: subset(subset_RI, cue == &quot;boundary&quot;) ## Models: ## modelMiniBoundaryControl: relativeAngle ~ 1 + (1 + mini | ID) ## modelMiniblocksBoundary: relativeInfluence ~ mini + (1 + mini | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelMiniBoundaryControl 5 121.7 145.37 -55.851 111.7 ## modelMiniblocksBoundary 6 -430.3 -401.90 221.152 -442.3 554.01 1 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Cue Dissonance As we decided to recode relative influence score to dCorrect / (dCorrect + dOther), we ran the main model with miniblocks again with the new dependent variable to see if the slope differ despite the same direction of improvement. Random effects could not included interaction as this caused singular fit. #model with new recoded dependent variable - cue dissonance formulaCueDis_mini &lt;- &quot;cueDissonance ~ cueMM*mini + (1+mini+cueMM||ID)&quot; modelCueDis_mini &lt;- lme4::lmer(formula = formulaCueDis_mini, data=subset_RI) summary(modelCueDis_mini) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: cueDissonance ~ cueMM * mini + ((1 | ID) + (0 + mini | ID) + (0 + cueMM | ID)) ## Data: subset_RI ## ## REML criterion at convergence: -727 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.3207 -0.6972 -0.1375 0.5941 3.0882 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.0043867 0.06623 ## ID.1 mini 0.0003698 0.01923 ## ID.2 cueMM 0.0010099 0.03178 ## Residual 0.0349238 0.18688 ## Number of obs: 1691, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.372802 0.011941 31.221 ## cueMM -0.010574 0.006983 -1.514 ## mini -0.058210 0.005179 -11.240 ## cueMM:mini 0.026205 0.004066 6.445 ## ## Correlation of Fixed Effects: ## (Intr) cueMM mini ## cueMM 0.002 ## mini 0.000 -0.002 ## cueMM:mini -0.002 0.000 0.006 To test the significance of the interaction, we ran a likelihood ratio test comparing our model and a model with both cue and miniblock as predictors but without the interaction. #control model for interaction formulaCueDis_miniControl &lt;- &quot;cueDissonance ~ cueMM+mini + (1+mini+cueMM|ID)&quot; modelCueDis_miniControl &lt;- lme4::lmer(formula = formulaCueDis_miniControl, data=subset_RI) #likelihood ratio test ratioCueDis_mini &lt;- anova(modelCueDis_mini, modelCueDis_miniControl) ## refitting model(s) with ML (instead of REML) ratioCueDis_mini ## Data: subset_RI ## Models: ## modelCueDis_mini: cueDissonance ~ cueMM * mini + ((1 | ID) + (0 + mini | ID) + (0 + cueMM | ID)) ## modelCueDis_miniControl: cueDissonance ~ cueMM + mini + (1 + mini + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelCueDis_mini 8 -744.05 -700.59 380.03 -760.05 ## modelCueDis_miniControl 10 -699.90 -645.57 359.95 -719.90 0 2 1 To see whether the model including cue is better than a miniblock with random effect we ran a likelihood ratio test. #control model formulaJustCue &lt;- &quot;cueDissonance ~ mini + (1+mini+cueMM|ID)&quot; modelJustCue &lt;- lme4::lmer(formula = formulaJustCue, data=subset_RI) summary(modelJustCue) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: cueDissonance ~ mini + (1 + mini + cueMM | ID) ## Data: subset_RI ## ## REML criterion at convergence: -701.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.3810 -0.7220 -0.1305 0.5973 3.0240 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.0043988 0.06632 ## mini 0.0003489 0.01868 0.25 ## cueMM 0.0010709 0.03272 -0.06 0.12 ## Residual 0.0358102 0.18924 ## Number of obs: 1691, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.372183 0.011967 31.10 ## mini -0.057994 0.005156 -11.25 ## ## Correlation of Fixed Effects: ## (Intr) ## mini 0.140 #likelihood ratio test ratioMini &lt;- anova(modelCueDis_miniControl, modelJustCue) ## refitting model(s) with ML (instead of REML) ratioMini ## Data: subset_RI ## Models: ## modelJustCue: cueDissonance ~ mini + (1 + mini + cueMM | ID) ## modelCueDis_miniControl: cueDissonance ~ cueMM + mini + (1 + mini + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelJustCue 9 -699.63 -650.73 358.81 -717.63 ## modelCueDis_miniControl 10 -699.90 -645.57 359.95 -719.90 2.2696 1 0.1319 3.7 Age To test our main hypothesis, we ran mixed model including age and cue as main predictors with interaction. 3.7.1 Relative Influence Mixed Model As our initial dependent variable, we examine these two predictors (cue, age) first to relative influence scores. #full model formulaFull &lt;- &quot;relativeInfluence ~ age_c*cueMM + ( 1 + cueMM | ID)&quot; modelFull &lt;- lmer(formula = formulaFull, data=subset_RI) summary(modelFull) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeInfluence ~ age_c * cueMM + (1 + cueMM | ID) ## Data: subset_RI ## ## REML criterion at convergence: -500.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.9992 -0.7245 -0.0161 0.6819 3.2272 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.0009555 0.03091 ## cueMM 0.0035607 0.05967 -0.06 ## Residual 0.0406837 0.20170 ## Number of obs: 1691, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.510882 0.007122 71.733 ## age_c -0.001078 0.003097 -0.348 ## cueMM 0.126120 0.011098 11.364 ## age_c:cueMM 0.012260 0.004816 2.546 ## ## Correlation of Fixed Effects: ## (Intr) age_c cueMM ## age_c -0.038 ## cueMM -0.035 0.000 ## age_c:cueMM 0.000 -0.033 -0.032 The significance of the interaction was tested using likelihood ratio test. #control model controlFinalInt &lt;- &quot;relativeInfluence ~ age_c + cueMM + (1 + cueMM | ID)&quot; modelControl &lt;- lmer(formula = controlFinalInt, data=subset_RI) #likelihood ratio test ratioFullModel &lt;- anova(modelFull, modelControl) ## refitting model(s) with ML (instead of REML) ratioFullModel ## Data: subset_RI ## Models: ## modelControl: relativeInfluence ~ age_c + cueMM + (1 + cueMM | ID) ## modelFull: relativeInfluence ~ age_c * cueMM + (1 + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelControl 7 -514.05 -476.02 264.03 -528.05 ## modelFull 8 -518.33 -474.87 267.17 -534.33 6.2786 1 0.01222 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Cue specific analysis To see if age remains a significant predictor without cue, we ran mixed models separately for boundary-dependent and landmark-dependent objects and tested them with likelihood ratio test including only random intercepts for participants. #landmark-dependent objects formulaAgeLandmark &lt;- &quot;relativeInfluence ~ age_c + (1|ID)&quot; modelAgeLandmark &lt;- lme4::lmer(formula = formulaAgeLandmark, data=subset(subset_RI, cue==&quot;landmark&quot;)) summary(modelAgeLandmark) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeInfluence ~ age_c + (1 | ID) ## Data: subset(subset_RI, cue == &quot;landmark&quot;) ## ## REML criterion at convergence: -122.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.9484 -0.7580 -0.1991 0.6437 3.0128 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.004438 0.06662 ## Residual 0.047501 0.21795 ## Number of obs: 851, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.384889 0.013395 28.734 ## age_c -0.013402 0.005814 -2.305 ## ## Correlation of Fixed Effects: ## (Intr) ## age_c -0.033 #control model controlAgeLandmark &lt;- &quot;relativeInfluence ~ 1 + (1 |ID)&quot; modelControlAgeLandmark &lt;- lme4::lmer(formula = controlAgeLandmark, data=subset(subset_RI, cue==&quot;landmark&quot;)) #likelihood ratio test ratioAgeLandmark &lt;- anova(modelAgeLandmark, modelControlAgeLandmark) ## refitting model(s) with ML (instead of REML) ratioAgeLandmark ## Data: subset(subset_RI, cue == &quot;landmark&quot;) ## Models: ## modelControlAgeLandmark: relativeInfluence ~ 1 + (1 | ID) ## modelAgeLandmark: relativeInfluence ~ age_c + (1 | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelControlAgeLandmark 3 -126.86 -112.62 66.428 -132.85 ## modelAgeLandmark 4 -130.08 -111.10 69.041 -138.08 5.2269 1 0.02224 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #boundary-dependent objects formulaAgeBoundary &lt;- &quot;relativeInfluence ~ age_c +(1|ID)&quot; modelAgeBoundary &lt;- lme4::lmer(formula = formulaAgeBoundary, data=subset(subset_RI, cue==&quot;boundary&quot;)) summary(modelAgeBoundary) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeInfluence ~ age_c + (1 | ID) ## Data: subset(subset_RI, cue == &quot;boundary&quot;) ## ## REML criterion at convergence: -397.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2637 -0.5699 0.0992 0.7403 1.9852 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.004603 0.06785 ## Residual 0.033774 0.18378 ## Number of obs: 840, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.637045 0.012977 49.092 ## age_c 0.011138 0.005636 1.976 ## ## Correlation of Fixed Effects: ## (Intr) ## age_c -0.034 #control model controlAgeBoundary &lt;- &quot;relativeInfluence ~ 1 + (1 |ID)&quot; modelControlAgeBoundary &lt;- lme4::lmer(formula = controlAgeBoundary, data=subset(subset_RI, cue==&quot;boundary&quot;)) #likelihood ratio test ratioAgeBoundary &lt;- anova(modelAgeBoundary, modelControlAgeBoundary) ## refitting model(s) with ML (instead of REML) ratioAgeBoundary ## Data: subset(subset_RI, cue == &quot;boundary&quot;) ## Models: ## modelControlAgeBoundary: relativeInfluence ~ 1 + (1 | ID) ## modelAgeBoundary: relativeInfluence ~ age_c + (1 | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelControlAgeBoundary 3 -402.86 -388.66 204.43 -408.86 ## modelAgeBoundary 4 -404.77 -385.84 206.39 -412.77 3.9124 1 0.04793 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Graphs The graph below visualizes how the relative influence improves with age as seen in collected data. RI_final &lt;- ggplot(relativeInfluenceBlocks, aes(age, relativeInf, color=cue)) + # setting up color palette - scico tokyo scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, guide = FALSE) + # overall mean and se stat_summary(fun=mean, aes(group=cue), geom=&quot;point&quot;, size = 2) + stat_summary(fun.data=mean_se, aes(group=cue), geom=&quot;errorbar&quot;, size=0.8, width=0.1, alpha=0.95) + # line connecting the avergae values stat_summary(fun=mean, aes(group=cue), geom=&quot;line&quot;, size = 1.5) + # setting up a new color scale for better visibility of individual geom_points new_scale_color() + # single subject data points (1 per participant) geom_point(aes(color=cue)) + # new color scale - also scico tokyo but in smaller range scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.3, end=0.7, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + # 0.5 neutral score for reference geom_hline(yintercept = 0.5, linetype=2, alpha=0.6) + # chaning breaks and limits of both axis scale_x_continuous(breaks = c(8,9,10,11,12,13,14,15)) + scale_y_continuous(limits = c(0.2, 0.8), breaks = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)) + # changing labels and title labs(x= &quot;Age&quot;, y = &quot;Relative Influence (0-1)&quot;, title = &quot;Data&quot;, color=&quot;Cue&quot;) + # background setting theme_cowplot() # show the graph RI_final ## Warning: It is deprecated to specify `guide = FALSE` to remove a guide. Please use `guide = &quot;none&quot;` instead. The graph below visualizes the relative influence age-dependent improvement based on a mixed model predictions. # calculating values predicted by the mixed model RI_predict &lt;- ggeffects::ggpredict(modelFull, terms = c(&quot;age_c&quot;, &quot;cueMM&quot;)) %&gt;% as_tibble() %&gt;% mutate(cuePredict = factor(if_else(group == 1, true = &quot;boundary&quot;, false = &quot;landmark&quot;), levels = c(&quot;boundary&quot;, &quot;landmark&quot;))) RI_model &lt;- ggplot(RI_predict, aes(x = x, y = predicted, colour = cuePredict, fill = cuePredict)) + # plotting the prediction geom_line(size = 0.5) + # plotting the confidence levels geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = .2, linetype=0) + # setting up color and fill palette - scico tokyo scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_fill_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + # changing limits, breaks and labels of both axis scale_x_continuous(breaks = sort(unique(Sum_all$age_c)), labels = c(&quot;8&quot;, &quot;9&quot;, &quot;10&quot;, &quot;11&quot;, &quot;12&quot;, &quot;13&quot;, &quot;14&quot;, &quot;15&quot;)) + scale_y_continuous(breaks = c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8), limits = c(0.2, 0.8)) + # background setting theme_cowplot() + # changing labels and title labs(x=&quot;Age&quot;, y=&quot; &quot;, color=&quot;Cue&quot;, fill=&quot;Cue&quot;, title = &quot;Mixed Model&quot;) + # 0.5 neutral score for reference geom_hline(yintercept = 0.5, linetype=2, alpha=0.6) #show the graph RI_model # specifying the layout layout &lt;- &quot; AAAAA#BBBBBB AAAAA#BBBBBB AAAAA#BBBBBB &quot; g_final &lt;- RI_final + RI_model &amp; plot_layout(design=layout) &amp; # unifying aesthetical aspects, mainly text size and style theme(axis.title = element_text(size = 10), axis.text = element_text(size=10), legend.title = element_text(size=10), legend.text = element_text(size=10), legend.position = &quot;bottom&quot;, plot.title = element_text(size=12, face=&quot;italic&quot;), plot.tag = element_text(size = 10, face=&quot;bold&quot;)) &amp; # adding title and tags plot_annotation(title = &#39;Positional Memory&#39;, theme = theme(plot.title = element_text(size = 12, face=&quot;bold&quot;)), tag_levels = list(c(&#39;A&#39;, &#39;B&#39;))) #saving the graph assembly as pdf and png ggsave(&quot;relativeInfluence_final.pdf&quot;, plot=g_final, units = &quot;cm&quot;, width = 15, height = 9, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;relativeInfluence_final.png&quot;, plot=g_final, units = &quot;cm&quot;, width = 15, height = 9, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) #show the plot g_final 3.7.2 Cue dissonance Mixed Model Next, we tested whether the effect of age and age and cue interaction remain when using the new variable - cue dissonance (one direction recoded relative influence score) as dependent variable. formulaCueDis &lt;- &quot;cueDissonance ~ age_c*cueMM + ( 1 + cueMM | ID)&quot; modelCueDis &lt;- lmer(formula = formulaCueDis, data=subset_RI) summary(modelCueDis) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: cueDissonance ~ age_c * cueMM + (1 + cueMM | ID) ## Data: subset_RI ## ## REML criterion at convergence: -500.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.1509 -0.7591 -0.1555 0.5824 3.2272 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.0035610 0.05967 ## cueMM 0.0009555 0.03091 -0.06 ## Residual 0.0406836 0.20170 ## Number of obs: 1691, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.373880 0.011098 33.687 ## age_c -0.012260 0.004816 -2.546 ## cueMM -0.010882 0.007122 -1.528 ## age_c:cueMM 0.001078 0.003097 0.348 ## ## Correlation of Fixed Effects: ## (Intr) age_c cueMM ## age_c -0.032 ## cueMM -0.035 0.000 ## age_c:cueMM 0.000 -0.033 -0.038 #control model for interaction controlCueDis &lt;- &quot;cueDissonance ~ age_c + cueMM + (1 + cueMM | ID)&quot; modelControlCueDis &lt;- lmer(formula = controlCueDis, data=subset_RI) #likelihood ratio test ratioCueDis &lt;- anova(modelCueDis, modelControlCueDis) ## refitting model(s) with ML (instead of REML) ratioCueDis ## Data: subset_RI ## Models: ## modelControlCueDis: cueDissonance ~ age_c + cueMM + (1 + cueMM | ID) ## modelCueDis: cueDissonance ~ age_c * cueMM + (1 + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelControlCueDis 7 -520.20 -482.17 267.10 -534.20 ## modelCueDis 8 -518.33 -474.87 267.17 -534.33 0.127 1 0.7215 Explorative Is cue even significant predictor? #control model for cue as predictor controlCueDis_cue &lt;- &quot;cueDissonance ~ age_c + (1 + cueMM | ID)&quot; modelCueDis_cueControl &lt;- lmer(formula = controlCueDis_cue, data=subset_RI) #likelihood ratio test ratioCueDis_cue &lt;- anova(modelCueDis_cueControl, modelControlCueDis) ## refitting model(s) with ML (instead of REML) ratioCueDis_cue ## Data: subset_RI ## Models: ## modelCueDis_cueControl: cueDissonance ~ age_c + (1 + cueMM | ID) ## modelControlCueDis: cueDissonance ~ age_c + cueMM + (1 + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelCueDis_cueControl 6 -519.86 -487.26 265.93 -531.86 ## modelControlCueDis 7 -520.20 -482.17 267.10 -534.20 2.3493 1 0.1253 Adding miniblock as a predictor instead to find the best model. #control model for miniblock as predictor miniFullCueDis&lt;- &quot;cueDissonance ~ age_c + mini + (1 + cueMM | ID)&quot; modelCueDis_miniFull &lt;- lmer(formula = miniFullCueDis, data=subset_RI) summary(modelCueDis_miniFull) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: cueDissonance ~ age_c + mini + (1 + cueMM | ID) ## Data: subset_RI ## ## REML criterion at convergence: -694.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.3636 -0.7099 -0.1471 0.5963 3.0167 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.003720 0.06099 ## cueMM 0.001064 0.03261 -0.03 ## Residual 0.036249 0.19039 ## Number of obs: 1691, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.373527 0.011176 33.422 ## age_c -0.012060 0.004849 -2.487 ## mini -0.058385 0.004142 -14.096 ## ## Correlation of Fixed Effects: ## (Intr) age_c ## age_c -0.031 ## mini 0.000 -0.003 #likelihood ratio test ratioCueDis_miniFull &lt;- anova(modelCueDis_miniFull, modelCueDis_cueControl) ## refitting model(s) with ML (instead of REML) ratioCueDis_miniFull ## Data: subset_RI ## Models: ## modelCueDis_cueControl: cueDissonance ~ age_c + (1 + cueMM | ID) ## modelCueDis_miniFull: cueDissonance ~ age_c + mini + (1 + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelCueDis_cueControl 6 -519.86 -487.26 265.93 -531.86 ## modelCueDis_miniFull 7 -705.30 -667.27 359.65 -719.30 187.45 1 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Graphs The graph below visualizes how the cue dissonance improves with age as seen in collected data. CueDis_final &lt;- ggplot(relativeInfluenceBlocks, aes(age, cueDis, color=cue)) + theme_cowplot() + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, guide = FALSE) + stat_summary(fun=mean, aes(group=cue), geom=&quot;line&quot;, size = 1.5) + stat_summary(fun=mean, aes(group=cue), geom=&quot;point&quot;, size = 2) + stat_summary(fun.data=mean_se, aes(group=cue), geom=&quot;errorbar&quot;, size=0.8, width=0.1, alpha=0.95) + new_scale_color() + geom_point(aes(color=cue)) + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.3, end=0.7, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_x_continuous(breaks = c(8,9,10,11,12,13,14,15)) + scale_y_continuous(limits = c(0.2, 0.8), breaks = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)) + labs(x= &quot;Age&quot;, y = &quot;RCue Dissonance (0-1)&quot;, title = &quot;Data&quot;, color=&quot;Cue&quot;) + geom_hline(yintercept = 0.5, linetype=2, alpha=0.6) CueDis_final ## Warning: It is deprecated to specify `guide = FALSE` to remove a guide. Please use `guide = &quot;none&quot;` instead. The graph below visualizes the cue dissonance age-dependent improvement based on a mixed model predictions. CueDis_predict &lt;- ggeffects::ggpredict(modelCueDis, terms = c(&quot;age_c&quot;, &quot;cueMM&quot;)) %&gt;% as_tibble() %&gt;% mutate(cuePredict = factor(if_else(group == 1, true = &quot;boundary&quot;, false = &quot;landmark&quot;), levels = c(&quot;boundary&quot;, &quot;landmark&quot;))) CueDis_model &lt;- ggplot(CueDis_predict, aes(x = x, y = predicted, colour = cuePredict, fill = cuePredict)) + geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = .2, linetype=0) + geom_line(size = 0.5) + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_fill_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_x_continuous(breaks = sort(unique(Sum_all$age_c)), labels = c(&quot;8&quot;, &quot;9&quot;, &quot;10&quot;, &quot;11&quot;, &quot;12&quot;, &quot;13&quot;, &quot;14&quot;, &quot;15&quot;)) + scale_y_continuous(breaks = c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8), limits = c(0.2, 0.8)) + theme_cowplot() + labs(x=&quot;Age&quot;, y=&quot; &quot;, color=&quot;Cue&quot;, fill=&quot;Cue&quot;, title = &quot;Mixed Model&quot;) + theme(legend.position = &quot;none&quot;) + geom_hline(yintercept = 0.5, linetype=2, alpha=0.6) CueDis_model Assembly of the generated graphs. layout &lt;- &quot; AAAAA#BBBBBB AAAAA#BBBBBB AAAAA#BBBBBB &quot; CueDis_final &lt;- CueDis_final + CueDis_model &amp; plot_layout(design=layout) &amp; theme(axis.title = element_text(size = 10), axis.text = element_text(size=10), legend.title = element_text(size=10), legend.text = element_text(size=10), legend.position = &quot;bottom&quot;, plot.title = element_text(size=12, face=&quot;italic&quot;), plot.tag = element_text(size = 10, face=&quot;bold&quot;)) &amp; plot_annotation(title = &#39;Positional Memory&#39;, theme = theme(plot.title = element_text(size = 12, face=&quot;bold&quot;)), tag_levels = list(c(&#39;A&#39;, &#39;B&#39;))) CueDis_final ggsave(&quot;cueDissonance_full.pdf&quot;, plot=CueDis_final, units = &quot;cm&quot;, width = 15, height = 9, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;cueDissonance_full.png&quot;, plot=CueDis_final, units = &quot;cm&quot;, width = 15, height = 9, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) 3.7.3 Distance error Mixed Model To see if age and cue can predict raw distance error, we ran the same analysis as above but with error in virtual meters as a dependent variable. formulaFullDist &lt;- &quot;error ~ age_c*cueMM + ( 1 + cueMM | ID)&quot; modelFullDist &lt;- lmer(formula = formulaFullDist, data=subset_RI) summary(modelFullDist) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: error ~ age_c * cueMM + (1 + cueMM | ID) ## Data: subset_RI ## ## REML criterion at convergence: 11436.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.3403 -0.6507 -0.2513 0.4080 4.6841 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 5.861 2.421 ## cueMM 0.757 0.870 0.35 ## Residual 48.092 6.935 ## Number of obs: 1691, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 9.79858 0.43762 22.390 ## age_c -0.74415 0.18984 -3.920 ## cueMM 0.34801 0.22269 1.563 ## age_c:cueMM -0.02019 0.09691 -0.208 ## ## Correlation of Fixed Effects: ## (Intr) age_c cueMM ## age_c -0.031 ## cueMM 0.215 -0.007 ## age_c:cueMM -0.007 0.215 -0.040 #control model for interaction controlFullDist&lt;- &quot;error ~ age_c + cueMM + (1 + cueMM | ID)&quot; modelControlFullDist &lt;- lmer(formula = controlFullDist, data=subset_RI) #likelihood ratio test ratioFullDist &lt;- anova(modelFullDist, modelControlFullDist) ## refitting model(s) with ML (instead of REML) ratioFullDist ## Data: subset_RI ## Models: ## modelControlFullDist: error ~ age_c + cueMM + (1 + cueMM | ID) ## modelFullDist: error ~ age_c * cueMM + (1 + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelControlFullDist 7 11445 11483 -5715.5 11431 ## modelFullDist 8 11447 11490 -5715.5 11431 0.0456 1 0.8309 Explorative Is cue even significant predictor? #control model for cue as predictor controlFullDist&lt;- &quot;error ~ age_c + (1 + cueMM | ID)&quot; modelControlFullDist &lt;- lmer(formula = controlFullDist, data=subset_RI) #likelihood ratio test ratioCueDist &lt;- anova(modelFullDist, modelControlFullDist) ## refitting model(s) with ML (instead of REML) ratioCueDist ## Data: subset_RI ## Models: ## modelControlFullDist: error ~ age_c + (1 + cueMM | ID) ## modelFullDist: error ~ age_c * cueMM + (1 + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelControlFullDist 6 11446 11478 -5716.7 11434 ## modelFullDist 8 11447 11490 -5715.5 11431 2.5151 2 0.2843 Adding miniblock instead of cue a predictor. #control model for miniblock as predictor miniFullDist&lt;- &quot;error ~ age_c + mini + (1 + cueMM | ID)&quot; modelMiniFullDist &lt;- lmer(formula = miniFullDist, data=subset_RI) summary(modelMiniFullDist) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: error ~ age_c + mini + (1 + cueMM | ID) ## Data: subset_RI ## ## REML criterion at convergence: 11216 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.7082 -0.6279 -0.1930 0.4095 5.1226 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 6.1288 2.4756 ## cueMM 0.9219 0.9601 0.36 ## Residual 41.9717 6.4786 ## Number of obs: 1691, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 9.6262 0.4287 22.457 ## age_c -0.7262 0.1859 -3.906 ## mini -2.1684 0.1409 -15.385 ## ## Correlation of Fixed Effects: ## (Intr) age_c ## age_c -0.031 ## mini 0.001 -0.003 #likelihood ratio test ratioFullMiniDist &lt;- anova(modelMiniFullDist, modelControlFullDist) ## refitting model(s) with ML (instead of REML) ratioFullMiniDist ## Data: subset_RI ## Models: ## modelControlFullDist: error ~ age_c + (1 + cueMM | ID) ## modelMiniFullDist: error ~ age_c + mini + (1 + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelControlFullDist 6 11446 11478 -5716.7 11434 ## modelMiniFullDist 7 11226 11265 -5606.3 11212 220.94 1 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Graphs distance_final &lt;- ggplot(relativeInfluenceBlocks, aes(age, distanceError, color=cue)) + theme_cowplot() + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, guide = FALSE) + stat_summary(fun=mean, aes(group=cue), geom=&quot;line&quot;, size = 1.5) + stat_summary(fun=mean, aes(group=cue), geom=&quot;point&quot;, size = 2) + stat_summary(fun.data=mean_se, aes(group=cue), geom=&quot;errorbar&quot;, size=0.8, width=0.1, alpha=0.95) + new_scale_color() + geom_point(aes(color=cue)) + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.3, end=0.7, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_x_continuous(breaks = c(8,9,10,11,12,13,14,15)) + labs(x= &quot;Age&quot;, y = &quot;Distance error (vm)&quot;, title = &quot;Data&quot;, color=&quot;Cue&quot;) distance_final ## Warning: It is deprecated to specify `guide = FALSE` to remove a guide. Please use `guide = &quot;none&quot;` instead. distance_predict &lt;- ggeffects::ggpredict(modelFullDist, terms = c(&quot;age_c&quot;, &quot;cueMM&quot;)) %&gt;% as_tibble() %&gt;% mutate(cuePredict = factor(if_else(group == 1, true = &quot;boundary&quot;, false = &quot;landmark&quot;), levels = c(&quot;boundary&quot;, &quot;landmark&quot;))) distance_model &lt;- ggplot(distance_predict, aes(x = x, y = predicted, colour = cuePredict, fill = cuePredict)) + geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = .2, linetype=0) + geom_line(size = 0.5) + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_fill_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_x_continuous(breaks = sort(unique(Sum_all$age_c)), labels = c(&quot;8&quot;, &quot;9&quot;, &quot;10&quot;, &quot;11&quot;, &quot;12&quot;, &quot;13&quot;, &quot;14&quot;, &quot;15&quot;)) + theme_cowplot() + labs(x=&quot;Age&quot;, y=&quot; &quot;, color=&quot;Cue&quot;, fill=&quot;Cue&quot;, title = &quot;Mixed Model&quot;) + theme(legend.position = &quot;none&quot;) distance_model layout &lt;- &quot; AAAAA#BBBBBB AAAAA#BBBBBB AAAAA#BBBBBB &quot; g_final_distance &lt;- distance_final + distance_model &amp; plot_layout(design=layout) &amp; theme(axis.title = element_text(size = 10), axis.text = element_text(size=10), legend.title = element_text(size=10), legend.text = element_text(size=10), legend.position = &quot;bottom&quot;, plot.title = element_text(size=12, face=&quot;italic&quot;), plot.tag = element_text(size = 10, face=&quot;bold&quot;)) &amp; plot_annotation(title = &#39;Positional Memory&#39;, theme = theme(plot.title = element_text(size = 12, face=&quot;bold&quot;)), tag_levels = list(c(&#39;A&#39;, &#39;B&#39;))) g_final_distance ggsave(&quot;distanceError_final.pdf&quot;, plot=g_final_distance, units = &quot;cm&quot;, width = 15, height = 9, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;distanceError_final.png&quot;, plot=g_final_distance, units = &quot;cm&quot;, width = 15, height = 9, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) "],["angle-estimation-analysis.html", "4 Angle estimation analysis 4.1 Set up 4.2 Descriptives 4.3 Block 1 Performance 4.4 Cue Differences 4.5 Miniblocks Learning 4.6 Age", " 4 Angle estimation analysis 4.1 Set up knitr::opts_chunk$set(echo = TRUE) Packages used for data analysis library(lme4) library(tidyverse) library(broom) library(ggsignif) library(patchwork) library(gghalves) library(cowplot) library(scico) library(Cairo) library(ggnewscale) library(here) library(effsize) library(pwr) ## Warning: package &#39;pwr&#39; was built under R version 4.0.2 library(circular) ## Warning: package &#39;circular&#39; was built under R version 4.0.2 ## Package &#39;circular&#39;, 0.4-93 (2017-06-26). Type &#39;help(Circular)&#39; for summary information. ## Please report any bug or comments to Claudio Agostinelli &lt;claudio.agostinelli@unitn.it&gt; ## ## Attaching package: &#39;circular&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## sd, var Functions written for this analysis #function circleFun() generates locations of 100 points that are in shape of circle #used for mapping out the arena in graphs circleFun &lt;- function(center = c(0,0), r = 27.5, npoints = 100){ tt &lt;- seq(0,2*pi,length.out = npoints) xx &lt;- center[1] + r * cos(tt) yy &lt;- center[2] + r * sin(tt) return(data.frame(x = xx, y = yy)) } circleSome &lt;- function(centerX, centerY, r = 27.5, npoints = 100, a1, a2){ tt &lt;- seq(a1,a2,length.out = npoints) xx &lt;- centerX + r * cos(tt) yy &lt;- centerY + r * sin(tt) return(data.frame(x = xx, y = yy)) } Loading in the full dataset Sum_all &lt;- read_delim(here(&quot;data&quot; ,&quot;Sum.txt&quot;), delim = &quot; &quot;, col_names = TRUE, col_types = &quot;fdddddddfcdddddddddddddddddddddddddddddddddddddddd&quot;) Creating a list of subject IDs from the full dataset subjects &lt;- unique(Sum_all$ID) 4.1.1 Timeout session Identifying and filtering timeout sessions i.e. trials with time over 59 seconds between trial beginning and angle estimation #summary of timeout trials timeout &lt;- filter(Sum_all, secTrialEst &gt; 59) print(sprintf(&quot;# timeout trials: %s&quot;, nrow(timeout))) ## [1] &quot;# timeout trials: 6&quot; print(sprintf(&quot;# participants with timeout trials: %s&quot;, length(unique(timeout$ID)))) ## [1] &quot;# participants with timeout trials: 6&quot; print(sprintf(&quot;average # timeout trials per participant with timeout trials: %s&quot;, nrow(timeout)/length(unique(timeout$ID)))) ## [1] &quot;average # timeout trials per participant with timeout trials: 1&quot; print(sprintf(&quot;average # timeout trials per participant: %s&quot;, nrow(timeout)/length(subjects))) ## [1] &quot;average # timeout trials per participant: 0.157894736842105&quot; #filtering timeout trials as they do not include location estimation Sum_all &lt;- filter(Sum_all, secTrialEst &lt; 59) 4.1.2 Exclusion criteria Participants are excluded based on positional memory performance in block 1 which is quantified using memory scores. To be included in the analysis, participant’s memory scores from block 1 need to be significantly greater than the chance level 0.5. exclusion &lt;- c() #creating empty list that will contain the subject IDs that will be excluded for (i_sub in subjects) { score &lt;- t.test(subset(Sum_all, ID==i_sub &amp; block==1)$memoryScoreTraj, mu=0.5, alternative = &quot;greater&quot;) %&gt;% tidy() #one-tailed t.test of block 1 memory scores against chance level 0.5 if (score$p.value &gt; 0.05) { exclusion &lt;- c(exclusion, i_sub) Sum_all &lt;- filter(Sum_all, ID != i_sub) } } print(sprintf(&quot;# participants excluded: %s&quot;, length(exclusion))) ## [1] &quot;# participants excluded: 2&quot; print(sprintf(&quot;new overall sample size: %s&quot;, length(subjects)-length(exclusion))) ## [1] &quot;new overall sample size: 36&quot; 4.2 Descriptives Reaction Time We looked into reaction time (seconds between end of target object display and angle estimation). #average RT reaction_time_dat &lt;- Sum_all %&gt;% group_by(ID, age) %&gt;% summarise(estResponse = mean(secTrialEst-3.5), .groups = &quot;drop&quot;) #discounting 3.5s for a target display at the beginning of each trial when participants are locked in their position #graph showing distribution, 1 point per participant ggplot(reaction_time_dat, aes(x=0, y=estResponse)) + geom_half_violin(aes(x=-0.05), fill=scico(1, palette = &quot;acton&quot;, begin = 0.45), alpha =0.5, color=NA) + geom_point(aes(x=0.105, color=age), position = position_jitter(width =0.05, height = 0), shape=16, size = 2) + scale_color_scico(palette = &quot;acton&quot;) + geom_boxplot(width = .08, outlier.shape = NA) + theme_cowplot() + ylab(&#39;RT&#39;) + xlab(&#39;&#39;) + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), aspect.ratio =1, plot.title = element_text(face=&quot;italic&quot;, size=12)) + scale_y_continuous(limits=c(0, 15)) #actual average RT and sd reaction_time &lt;- summarise(reaction_time_dat, mean = mean(estResponse), sd=sd(estResponse), min=min(estResponse), max=max(estResponse)) reaction_time ## # A tibble: 1 × 4 ## mean sd min max ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6.60 2.51 2.83 12.2 print(sprintf(&quot;The average reaction time for pointing was %s seconds (sd = %s).&quot;, round(reaction_time$mean, 3), round(reaction_time$sd, 3))) ## [1] &quot;The average reaction time for pointing was 6.601 seconds (sd = 2.514).&quot; 4.3 Block 1 Performance This subsection of the analysis aims to answer whether the participants completed the basic task according to the instructions before any manipulation was introduced. Did they understand how to rotate and indicate their angle estimation? 4.3.1 Raw Angle Error Visualization First, let’s look on how participants performed by examining the signed angle error distribution. 0° as “correct angle”. g_anglB1 &lt;- ggplot(Sum_all %&gt;% filter(block == 1), aes(x = angleError)) + # creating histogram to see the distribution geom_histogram(binwidth = 10, boundary=0, fill = scico(1, palette = &quot;lajolla&quot;, begin=0.5), color= &quot;black&quot;, size = .25) + # rounding the histogram to 360° circle coord_polar(start=pi) + # specifying the limits and breaks scale_x_continuous(limits = c(-180,180), breaks = seq(-180, 180, by = 45), minor_breaks = seq(-180, 180, by = 15)) + # background/plot style theme_cowplot() + background_grid() + # changing labels and title labs(x = &quot;Pointing Error (°)&quot;, y = &quot;Count&quot;, title = &quot;Signed Distribution of Error&quot;) + theme(axis.title.y = element_text(hjust = 0.7)) g_anglB1 4.3.2 Angle Error Stats Data summarizing for each participant for block 1. summaryBlock1_Angle &lt;- Sum_all %&gt;% filter(block==1) %&gt;% group_by(ID, block) %&gt;% summarise(angleErr = mean(abs(angleError)), .groups=&quot;drop&quot;) T-Test We took 90° as a threshold of randomness (possible absolute angle error 0-180°). To see whether participants pointed better than on average randomly, we ran a one sample, one-tailed t-test of their average absolute angle error in block 1 against 90. To see the effect size we calculated cohen’s d. t.test(summaryBlock1_Angle$angleErr, mu = 90, alternative = &quot;less&quot;) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 20.8 -34.4 7.25e-29 35 -Inf 24.2 One Sample t-test less cohen.d(d=summaryBlock1_Angle$angleErr, f=NA, mu=90) ## ## Cohen&#39;s d (single sample) ## ## d estimate: -5.729989 (large) ## Reference mu: 90 ## 95 percent confidence interval: ## lower upper ## -7.258813 -4.201166 Graph The graph below shows the average absolute angle error in block 1 for each participant and consequentially the distribution of these values. g_errB1 &lt;- ggplot(summaryBlock1_Angle, aes(x=block, y=angleErr)) + # violin plot geom_half_violin(aes(x=block-0.05), fill=scico(1, palette= &quot;lajolla&quot;, begin = 0.45), alpha =0.5, color=NA) + # single subject data points (1 per participant) with horizontal jitter geom_point(aes(x=block+0.07), position = position_jitter(width =0.02, height = 0), shape=16, size = 1) + # boxplot (median, quartiles) geom_boxplot(width = .05, outlier.shape = NA) + # adding plot of mean and SEM stat_summary(fun = mean, geom = &quot;point&quot;, size=1, shape = 16, position = position_nudge(-.05), colour = &quot;black&quot;) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;, position = position_nudge(-.05), colour = &quot;black&quot;, width = 0, size = 0.5) + geom_hline(yintercept = 90, linetype=2) + annotate(&quot;text&quot;, label = &quot;90°&quot;, x = 1.3, y = 85, size = 3) + labs(y=&#39;Pointing Error (°)&#39;, x=&#39; &#39;, title = &quot;Average Absolute Error&quot;) + theme_cowplot() + theme(axis.title = element_text(size=10), axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.text.y = element_text(size=10)) #show graph g_errB1 Assembly of block 1 graphs for pointing task. angleEst_B1 &lt;- g_errB1 + g_anglB1 &amp; # unifying aesthetics theme(axis.title = element_text(size=12), plot.title = element_text(face=&quot;italic&quot;, size=12)) &amp; # assembly title plot_annotation(title = &#39;Pointing Errors&#39;, theme = theme(plot.title = element_text(size = 14, face=&quot;bold&quot;))) # saving as pdf and png ggsave(file=&quot;AngleErrors_B1.pdf&quot;, plot=angleEst_B1, units = &quot;cm&quot;, width = 15.9, height = 10, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(file=&quot;AngleErrors_B1.png&quot;, plot=angleEst_B1, units = &quot;cm&quot;, width = 15.9, height = 10, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) angleEst_B1 Assembly of block 1 graphs for positional memory and pointing task. block1_graphs &lt;- memory_B1 / angleEst_B1 &amp; # unifying aesthetics theme(axis.title = element_text(size=10), axis.text = element_text(size=10), plot.title = element_text(face=&quot;italic&quot;, size=12), legend.text = element_text(size=10), legend.title = element_text(size=10), plot.tag = element_text(size = 10, face=&quot;bold&quot;)) &amp; # assembly title, subtitle and tags plot_annotation(title = &#39;Block 1 Performance&#39;, subtitle = &#39; \\nPositional Memory&#39;, theme = theme(plot.title = element_text(size = 14, face=&quot;bold&quot;), plot.subtitle = element_text(size=12, face=&quot;bold&quot;)), tag_levels = &#39;A&#39;) #saving as pdf and png ggsave(file=&quot;B1.pdf&quot;, plot=block1_graphs, units = &quot;cm&quot;, width = 15, height = 16, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(file=&quot;B1.png&quot;, plot=block1_graphs, units = &quot;cm&quot;, width = 15, height = 16, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) block1_graphs 4.4 Cue Differences Next we wanted to investigate whether the participants followed the cues in block 2-4 after landmark and landmark-dependent object movement. Also, is there performance difference between landmark- vs boundary-dependent objects? 4.4.1 Relative Influence To evaluate, which cue participants are using to remember the direction of target object we used relative influence which was created and first used by Doeller, King and Burgess (2008). However, we were the first to use this measurement for angle estimation/pointing. The graph below shows the calculation. Explanation Graph #loading a data from block 2-4 for a single participant graph_sub &lt;- filter(Sum_all, ID == i_sub &amp; block == 2 &amp; trial==5) # generating points that will form arena boundary circle &lt;- circleFun() # generating points that will form angle difference between estimated angle and angle predicted by boundary angle1 &lt;- circleSome(centerX= graph_sub$charX, centerY= graph_sub$charY, r=15, a1= 1.5707963268-rad(graph_sub$estAngle), a2=1.5707963268-rad(graph_sub$boundaryAngle)) # generating points that will form angle difference between estimated angle and angle predicted by landmark angle2 &lt;- circleSome(centerX= graph_sub$charX, centerY= graph_sub$charY, r=10, a1= 1.5707963268-rad(graph_sub$estAngle), a2=1.5707963268-rad(graph_sub$landmarkAngle)) relativeAng_graph &lt;- ggplot(data=graph_sub) + # location predicted by landmark geom_point(aes(x=landmarkCuePosX, y=landmarkCuePosY, color=&quot;Angle Predicted by Landmark&quot;), size = 1.5, alpha=0.3) + # line visualizing the angle from participant&#39;s position to the object location predicted by landmark geom_segment(aes(x=charX, y=charY, xend= landmarkCuePosX, yend=landmarkCuePosY, color=&quot;Angle Predicted by Landmark&quot;), alpha=.9) + # adding aL label annotate(&quot;text&quot;, label=&quot;aL&quot;, x=-3, y=2, size=4, color=&quot;#C6F1B1&quot;, fontface =2) + # location predicted by boundary geom_point(aes(x=boundaryCuePosX, y=boundaryCuePosY, color=&quot;Angle Predicted by Boundary&quot;), size = 1.5, alpha=0.3) + # line visualizing the angle from participant&#39;s position to the object location predicted by boundary geom_segment(aes(x=boundaryCuePosX, y=boundaryCuePosY, xend= charX, yend= charY, color=&quot;Angle Predicted by Boundary&quot;), alpha=.9) + # adding dB label annotate(&quot;text&quot;, label=&quot;aB&quot;, x=-4.5, y=-5, size=4, color=&quot;#592758&quot;, fontface =2) + #participants location geom_point(aes(x=charX, y=charY, color = &quot;Estimated Angle&quot;), size = 2.5) + annotate(&quot;text&quot;, label=&quot;Participant&#39;s location&quot;, x= -12, y = 12, size=3.5, color= &quot;red&quot;) + #landmark location geom_point(aes(x=landmarkX, y=landmarkY), shape = 15, color = &quot;#94A98F&quot;, size=3) + annotate(&quot;text&quot;, label=&quot;Landmark&quot;, x= 14, y = 8.8, size=3.5, color= &quot;#94A98F&quot;) + #estimated angle geom_spoke(mapping =aes(x=charX, y=charY, angle = 1.5707963268-rad(estAngle), radius =20), color=&quot;red&quot;, linetype = 1, alpha=0.8) + # angle difference between angle predicted by boundary and estimated angle geom_path(data=angle1, aes(x,y, color=&quot;Angle Predicted by Boundary&quot;))+ # angle difference between angle predicted by landmark and estimated angle geom_path(data=angle2, aes(x,y,color=&quot;Angle Predicted by Landmark&quot;))+ # creating arena boundary geom_path(data=circle, aes(x, y)) + # aesthetical changes theme_cowplot() + theme(aspect.ratio=1, axis.title = element_text(size=10), axis.text = element_text(size=10), plot.title = element_text(size=12), plot.subtitle = element_text(size = 11)) + # changing labels and title labs(title = &quot;Relative Influence Calculation for Angle Estimation&quot;, subtitle = paste(&quot;aL / (aL + aB) &quot;, sprintf(&quot;Angle Relative Influence: %s &quot;, round(graph_sub$relativeAngle, 2)), sep=&quot;\\n&quot;), x= &#39;X (vm)&#39;, y= &#39;Y (vm)&#39;) + # specifying colors manually scale_color_manual(name = &quot; &quot;, values= c(&quot;Angle Predicted by Boundary&quot; = &quot;#592758&quot;, &quot;Angle Predicted by Landmark&quot; = &quot;#C6F1B1&quot;, &quot;Estimated Angle&quot; = &quot;red&quot;)) # saving graph as pdf and png ggsave(filename=&quot;relative_angle_visual.pdf&quot;, plot=relativeAng_graph, units = &quot;cm&quot;, width = 15, height = 11, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;relative_angle_visual.png&quot;, plot=relativeAng_graph, units = &quot;cm&quot;, width = 15, height = 11, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) # show the graph relativeAng_graph Let’s subset and summarize data for blocks 2-4. subset_RA &lt;- Sum_all %&gt;% filter(block!=1) %&gt;% select(ID, age, age_c, block, miniblock, mini, objectTrial, trial, cue, cueMM, angleError, relativeAngle, cueDissonanceAngle) relativeAngleBlocks &lt;- subset_RA %&gt;% group_by(ID, cue, age) %&gt;% summarise(angleErr = mean(abs(angleError)), relativeAng = mean(relativeAngle), raSD = sd(relativeAngle), cueDisA = mean(cueDissonanceAngle), .groups=&quot;drop&quot;) T-Tests As score 0.5 points towards angle between the angle predicted by landmark and angle predicted by boundary, we ran a one sample, one tail t-test to test whether the relative scores for landmark-dependent objects are less than 0.5. t.test(subset(relativeAngleBlocks, cue==&quot;landmark&quot;)$relativeAng, mu = 0.5, alternative = &quot;less&quot;) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.377 -7.63 0.00000000299 35 -Inf 0.405 One Sample t-test less cohen.d(d=subset(relativeAngleBlocks, cue==&quot;landmark&quot;)$relativeAng, f=NA, mu = 0.5) ## ## Cohen&#39;s d (single sample) ## ## d estimate: -1.271776 (large) ## Reference mu: 0.5 ## 95 percent confidence interval: ## lower upper ## -2.0137388 -0.5298135 After we ran a one sample, one tail t-test to test whether the relative scores for boundary-dependent objects are higher than 0.5. t.test(subset(relativeAngleBlocks, cue==&quot;boundary&quot;)$relativeAng, mu = 0.5, alternative = &quot;greater&quot;) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.586 7.87 0.00000000149 35 0.568 Inf One Sample t-test greater cohen.d(d=subset(relativeAngleBlocks, cue==&quot;boundary&quot;)$relativeAng, f=NA, mu = 0.5) ## ## Cohen&#39;s d (single sample) ## ## d estimate: 1.311865 (large) ## Reference mu: 0.5 ## 95 percent confidence interval: ## lower upper ## 0.5659176 2.0578120 We also tested these two groups against each other to see if the scores are significantly different. t.test(subset(relativeAngleBlocks, cue==&quot;boundary&quot;)$relativeAng, subset(relativeAngleBlocks, cue==&quot;landmark&quot;)$relativeAng, paired = TRUE) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.209 9.38 4.41e-11 35 0.164 0.254 Paired t-test two.sided cohen.d(subset(relativeAngleBlocks, cue==&quot;boundary&quot;)$relativeAng, subset(relativeAngleBlocks, cue==&quot;landmark&quot;)$relativeAng, paired=TRUE) ## ## Cohen&#39;s d ## ## d estimate: 2.553011 (large) ## 95 percent confidence interval: ## lower upper ## 1.432709 3.673314 pwr.t.test(n = 36, d = 2.532636, sig.level = 0.05, power = NULL, type = c(&quot;paired&quot;), alternative = c(&quot;two.sided&quot;)) ## ## Paired t test power calculation ## ## n = 36 ## d = 2.532636 ## sig.level = 0.05 ## power = 1 ## alternative = two.sided ## ## NOTE: n is number of *pairs* Graph This difference in relative influence scores between boundary-dependent objects and landmark-dependent objects is visualized in a graph below. rel_InfAng &lt;- ggplot(relativeAngleBlocks, aes(x=cue, y=relativeAng)) + # violin plots gghalves::geom_half_violin(data=relativeAngleBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.2), aes(fill=cue),alpha =0.7, color=NA, side=&quot;r&quot;) + gghalves::geom_half_violin(data=relativeAngleBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.2), aes(fill=cue),alpha =0.7, color=NA, side=&quot;l&quot;) + # scico palette tokyo scale_fill_scico_d(palette = &#39;tokyo&#39;, begin=0.15, end=0.85) + # single subject data points (1 per participant) geom_point(shape=16, size = 1) + # line connecting individual participants&#39; values geom_line(aes(group=ID), alpha=0.5) + # bowplot distribution geom_boxplot(data=relativeAngleBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.1), width = .1, outlier.shape = NA) + geom_boxplot(data= relativeAngleBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.1), width = .1, outlier.shape = NA) + # adding plot of mean and SEM stat_summary(data=relativeAngleBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.2), fun = mean, geom = &quot;point&quot;, size=1, shape = 16, colour = &quot;black&quot;) + stat_summary(data=relativeAngleBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.2), fun.data = mean_se, geom = &quot;errorbar&quot;, colour = &quot;black&quot;, width = 0, size = 0.5) + stat_summary(data=relativeAngleBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.2), fun = mean, geom = &quot;point&quot;, size=1, shape = 16, colour = &quot;black&quot;) + stat_summary(data=relativeAngleBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.2), fun.data = mean_se, geom = &quot;errorbar&quot;, colour = &quot;black&quot;, width = 0, size = 0.5) + # background setting theme_cowplot() + # changing axis labels and title labs(x = &quot; &quot;, y = &quot;Relative Influence (0-1)&quot;, title = &quot;Pointing&quot;) + # visualizing the significance levels of the t-test geom_signif(comparisons = list(c(&quot;landmark&quot;, &quot;boundary&quot;)), test=&quot;t.test&quot;, test.args=list(alternative = &quot;two.sided&quot;, paired=TRUE), map_signif_level = TRUE, tip_length = 0, extend_line = 0.045, y_position = 0.85) + # adding line at 0.5 (not-following either cue) geom_hline(yintercept=0.5, linetype=2, alpha=0.6) + # axis labels, limits and breaks scale_x_discrete(labels = c(&#39;Boundary&#39;, &#39;Landmark&#39;)) + scale_y_continuous(limits=c(0.1, 0.9), breaks = c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)) ggsave(&quot;relativeInfluenceAng.pdf&quot;, plot=rel_InfAng, units = &quot;cm&quot;, width = 15, height = 12, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;relativeInfluenceAng.png&quot;, plot=rel_InfAng, units = &quot;cm&quot;, width = 15, height = 12, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) rel_InfAng Assembly of relative influence plots for both positional memory and pointing. relative_infl &lt;- rel_Inf / rel_InfAng &amp; theme(axis.title = element_text(size=10), axis.text = element_text(size=10), plot.title = element_text(face=&quot;italic&quot;, size=12), plot.tag = element_text(size = 10, face=&quot;bold&quot;), legend.position = &quot;none&quot;) &amp; plot_annotation(title = &quot;Relative Influence&quot;, theme = theme(plot.title = element_text(size = 12, face=&quot;bold&quot;)), tag_levels = &#39;A&#39;) ggsave(&quot;relativeInfluenceAll.pdf&quot;, plot=relative_infl, units = &quot;cm&quot;, width = 11, height = 15, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;relativeInfluenceAll.png&quot;, plot=relative_infl, units = &quot;cm&quot;, width = 11, height = 15, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) relative_infl Mixed Model As a first step towards building a full mixed effects model, we tested a simpliest version with only cue as a fixed effect and a random slope and random intercepts for participants. We did not use cue as a factor but in a recoded version of landmark = -1 and boundary = 1. #formula formulaCue &lt;- &quot;relativeAngle ~ cueMM + (1+cueMM|ID)&quot; #model modelCueAngle &lt;- lme4::lmer(formula = formulaCue, data=subset_RA) summary(modelCueAngle) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeAngle ~ cueMM + (1 + cueMM | ID) ## Data: subset_RA ## ## REML criterion at convergence: 281.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.31145 -0.76645 -0.00303 0.75228 2.72534 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.0009263 0.03044 ## cueMM 0.0030423 0.05516 -0.73 ## Residual 0.0664054 0.25769 ## Number of obs: 1704, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.481416 0.008045 59.837 ## cueMM 0.104341 0.011115 9.388 ## ## Correlation of Fixed Effects: ## (Intr) ## cueMM -0.381 To test, whether cue is a significant predictor we ran a likelihood ratio test comparing our simpliest model and a model containing only random effects. #control model without cue as a predictor formulaControl &lt;- &quot;relativeAngle ~ 1 + (1+cueMM|ID)&quot; modelCueControl &lt;- lme4::lmer(formula = formulaControl, data=subset_RA) #likelihood ratio test ratioCueAngle &lt;- anova(modelCueAngle, modelCueControl) ## refitting model(s) with ML (instead of REML) ratioCueAngle ## Data: subset_RA ## Models: ## modelCueControl: relativeAngle ~ 1 + (1 + cueMM | ID) ## modelCueAngle: relativeAngle ~ cueMM + (1 + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelCueControl 5 321.85 349.06 -155.93 311.85 ## modelCueAngle 6 278.62 311.26 -133.31 266.62 45.233 1 1.749e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.4.2 Angle Error Difference Paired, two-tailed t-test to see if the angle error differs between trials with landmark-dependent and boundary-dependent objects. t.test(subset(relativeAngleBlocks, cue==&quot;boundary&quot;)$angleErr, subset(relativeAngleBlocks, cue==&quot;landmark&quot;)$angleErr, paired = TRUE) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1.27 0.791 0.434 35 -2.00 4.55 Paired t-test two.sided Graph below visualizes the lack of difference. cue_Ang &lt;- ggplot(relativeAngleBlocks, aes(x=cue, y= angleErr)) + #violin plots gghalves::geom_half_violin(data=relativeAngleBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.2), aes(fill=cue),alpha =0.7, color=NA, side=&quot;r&quot;) + gghalves::geom_half_violin(data=relativeAngleBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.2), aes(fill=cue),alpha =0.7, color=NA, side=&quot;l&quot;) + # setting scico palette tokyo as a fill for violin plots scale_fill_scico_d(palette = &#39;tokyo&#39;, begin=0.15, end=0.85) + # single subject data points (1 per participant) geom_point(shape=16, size = 1) + # line connecting individual participants&#39; values geom_line(aes(group=ID), alpha=0.5) + # boxplots geom_boxplot(data=relativeAngleBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.1), width = .1, outlier.shape = NA) + geom_boxplot(data=relativeAngleBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.1), width = .1, outlier.shape = NA) + # adding plot of mean and SEM stat_summary(data=relativeAngleBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.2), fun = mean, geom = &quot;point&quot;, size=1, shape = 16, colour = &quot;black&quot;) + stat_summary(data=relativeAngleBlocks %&gt;% filter(cue==&quot;landmark&quot;), position=position_nudge(+0.2), fun.data = mean_se, geom = &quot;errorbar&quot;, colour = &quot;black&quot;, width = 0, size = 0.5) + stat_summary(data=relativeAngleBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.2), fun = mean, geom = &quot;point&quot;, size=1, shape = 16, colour = &quot;black&quot;) + stat_summary(data=relativeAngleBlocks %&gt;% filter(cue==&quot;boundary&quot;), position=position_nudge(-0.2), fun.data = mean_se, geom = &quot;errorbar&quot;, colour = &quot;black&quot;, width = 0, size = 0.5) + # visualizing the significance level of the t-test geom_signif(comparisons = list(c(&quot;landmark&quot;, &quot;boundary&quot;)), test=&quot;t.test&quot;, test.args=list(alternative = &quot;two.sided&quot;, paired=TRUE), map_signif_level = TRUE, tip_length = 0, extend_line = 0.045, y_position = 92) + # background setting theme_cowplot() + # changing axis labels and title labs(x = &quot; &quot;, y = &quot;Pointing Error (°)&quot;, title = &quot;Pointing&quot;) + # changing axis limits, breaks and values scale_x_discrete(labels = c(&#39;Boundary&#39;, &#39;Landmark&#39;)) + scale_y_continuous(breaks = c(25, 50, 75, 100), limits = c(9,100)) ggsave(&quot;angleError.pdf&quot;, plot=cue_Ang, units = &quot;cm&quot;, width = 15.9, height = 12, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;angleError.png&quot;, plot=cue_Ang, units = &quot;cm&quot;, width = 15.9, height = 12, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) cue_Ang Assembling plots with raw error for both positional memory and pointing. cue_Diff &lt;- cue_Dist / cue_Ang &amp; theme(axis.title = element_text(size=10), axis.text = element_text(size=10), plot.title = element_text(face=&quot;italic&quot;, size=12), plot.tag = element_text(size = 10, face=&quot;bold&quot;), legend.position = &quot;none&quot;) &amp; plot_annotation(title = &quot;Raw Performance Differences&quot;, theme = theme(plot.title = element_text(size = 12, face=&quot;bold&quot;)), tag_levels = &#39;A&#39;) ggsave(&quot;cueDiffAll.pdf&quot;, plot=cue_Diff, units = &quot;cm&quot;, width = 11, height = 15, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;cueDiffAll.png&quot;, plot=cue_Diff, units = &quot;cm&quot;, width = 11, height = 15, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) cue_Diff 4.5 Miniblocks Learning 4.5.1 Graphs The graph below shows the relative influence scores averaged for each miniblock in block 2-4 (averaging over 6 scores for each miniblock) summary_miniblock_A &lt;- subset_RA %&gt;% group_by(ID, miniblock, cue, age) %&gt;% summarise(relativeAng = mean(relativeAngle), raSD = sd(relativeAngle), .groups = &quot;drop&quot;) g_miniAng &lt;- ggplot(summary_miniblock_A, aes(miniblock, relativeAng, group=interaction(cue, ID), color=cue)) + geom_line(size=0.8, alpha = 0.3) + stat_summary(data= subset(summary_miniblock_A, cue==&quot;boundary&quot;), fun.data=mean_se, aes(group=cue), geom=&quot;errorbar&quot;, width=0.1, position = position_nudge(x=0.01)) + stat_summary(data= subset(summary_miniblock_A, cue==&quot;landmark&quot;), fun.data=mean_se, aes(group=cue), geom=&quot;errorbar&quot;, width=0.1, position=position_nudge(x=-0.01)) + stat_summary(fun=mean, aes(group=cue), geom=&quot;line&quot;, size = 1.5) + stat_summary(fun=mean, aes(group=cue), geom=&quot;point&quot;, size=2) + geom_hline(yintercept = 0.5, linetype = 2) + theme_cowplot() + labs(x= &quot;Miniblock&quot;, y = &quot;Relative Influence (0-1)&quot;, title = &quot;Averaged across Blocks&quot;, color = &quot;Cue&quot;) + theme(plot.title = element_text(size=12, face=&quot;italic&quot;), axis.title = element_text(size=10), axis.text = element_text(size=10)) + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1), limits = c(0,1)) + scale_x_continuous(limits = c(0.5, 4.5), breaks = c(1,2,3,4)) g_miniAng The graph below shows the relative influence scores for each miniblock throughout block 2-4 (averaging only over 2 scores per miniblock) #data summarizing summary_objectTrial_A &lt;- subset_RA %&gt;% group_by(ID, objectTrial, cue) %&gt;% summarise(relativeAng = mean(relativeAngle), raSD = sd(relativeAngle), .groups=&quot;drop&quot;) #graph g_objTrialAng &lt;- ggplot(data=summary_objectTrial_A, aes(objectTrial, relativeAng, group=interaction(cue, ID), color=cue)) + theme_cowplot() + geom_line(data= subset(summary_objectTrial_A, objectTrial &lt; 9), size=0.8, alpha = 0.3) + geom_line(data= subset(summary_objectTrial_A, objectTrial &lt; 13 &amp; objectTrial &gt; 8), size=0.8, alpha = 0.3) + geom_line(data= subset(summary_objectTrial_A, objectTrial &gt; 12), size=0.8, alpha = 0.3) + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary, Landmark&quot;)) + labs(x= &quot;Miniblock&quot;, y = &quot;Relative Influence (0-1)&quot;, title= &quot;Separately per Block&quot;, color= &quot;Cue&quot;) + stat_summary(data = subset(summary_objectTrial_A, objectTrial &lt; 9), fun=mean, aes(group=cue), geom=&quot;line&quot;, size = 1.5) + stat_summary(data = subset(summary_objectTrial_A, objectTrial &lt; 13 &amp; objectTrial &gt; 8), fun=mean, aes(group=cue), geom=&quot;line&quot;, size = 1.5) + stat_summary(data = subset(summary_objectTrial_A, objectTrial &gt; 12), fun=mean, aes(group=cue), geom=&quot;line&quot;, size = 1.5) + stat_summary(data= subset(summary_objectTrial_A, cue==&quot;boundary&quot;), fun.data = mean_se, aes(group=cue), geom = &quot;errorbar&quot;, width=0.1, position = position_nudge(x=+0.01)) + stat_summary(data= subset(summary_objectTrial_A, cue==&quot;landmark&quot;), fun.data = mean_se, aes(group=cue), geom = &quot;errorbar&quot;, width=0.1, position = position_nudge(x=-0.01)) + stat_summary(fun=mean, aes(group=cue), geom=&quot;point&quot;, size=2) + geom_hline(yintercept = 0.5, linetype = 2) + geom_vline(xintercept = 8.9, alpha = 0.7, linetype=3) + geom_vline(xintercept = 12.9, alpha = 0.7, linetype=3) + geom_vline(xintercept = 4.9, alpha = 0.7, linetype=3) + scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1), limits = c(0,1)) + scale_x_continuous(breaks = c(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16), labels = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;)) + annotate(&quot;text&quot;, label = &quot;Block 2&quot;, x = 5.6, y = 1, size = 3) + annotate(&quot;text&quot;, label = &quot;Block 3&quot;, x = 9.6, y = 1, size = 3) + annotate(&quot;text&quot;, label = &quot;Block 4&quot;, x = 13.6, y = 1, size = 3) + theme(legend.position = &quot;none&quot;) g_objTrialAng Assembling the two plots above for more comprehensive visualization. layout &lt;- &quot; AAAAAA AAAAAA AAAAAA BB#### BB#C## BB#### &quot; g_leg &lt;- guide_area() g_minAng &lt;- g_objTrialAng + g_miniAng + g_leg + plot_layout(design = layout, guides = &quot;collect&quot;) &amp; theme(axis.title = element_text(size = 10), axis.text = element_text(size=10), legend.title = element_text(size=10), legend.text = element_text(size=10), plot.title = element_text(size=12, face=&quot;italic&quot;), plot.tag = element_text(size = 10, face=&quot;bold&quot;)) &amp; plot_annotation(title = &#39;Pointing Error&#39;, theme = theme(plot.title = element_text(size = 12, face=&quot;bold&quot;)), tag_levels = list(c(&#39;C&#39;, &#39;D&#39;))) g_minAng ggsave(&quot;relativeAngle_min.pdf&quot;, plot=g_minAng, units = &quot;cm&quot;, width = 15, height = 13, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;relativeAngle_min.png&quot;, plot=g_minAng, units = &quot;cm&quot;, width = 15, height = 13, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) 4.5.2 Miniblock 1 We noticed that there is a tendency for relative influence score to be above regardless cue-dependency so we wanted to test this statistically so we ran a one-sided, one sample t-test against 0.5. # summarizing by ID for all miniblocks 1 (in block 2-4) sub_mini_1A &lt;- subset_RA %&gt;% filter(miniblock == 1) %&gt;% group_by(ID) %&gt;% summarise(relAngle = mean(relativeAngle), .groups =&quot;drop&quot;) # one-tailed, one sample t-test t.test(sub_mini_1A$relAngle, mu=0.5, alternative = &quot;greater&quot;) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.532 2.24 0.0158 35 0.508 Inf One Sample t-test greater As it seems the relative influence in miniblock is indeed higher than 0.5, therefore they are more likely following boundary as a cue (its old location). Next, we wanted to ensure that there is indeed no difference between the relative influence score between landmark-dependent and boundary-dependent objects in miniblock 1. # summarizing by ID and cue for all miniblocks 1 (in blocks 2-4) sub_mini_cueA &lt;- subset_RA %&gt;% filter(miniblock == 1) %&gt;% group_by(ID, cue) %&gt;% summarise(relAngle = mean(relativeAngle), .groups =&quot;drop&quot;) # two-tailed, paired sample t-test t.test(subset(sub_mini_cueA, cue==&quot;landmark&quot;)$relAngle, subset(sub_mini_cueA, cue==&quot;boundary&quot;)$relAngle, paired=TRUE) %&gt;% tidy() ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method alternative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 -0.0108 -0.340 0.736 35 -0.0755 0.0539 Paired t-test two.sided 4.5.3 Mixed Models Relative Influence To test the learning throughout a block, we ran mixed effect model with interaction between cue and miniblock (centered) and added interaction between miniblock and cue as a random slope. #formula formulaMiniblocks &lt;- &quot;relativeAngle ~ cue*mini + (1+mini:cueMM|ID)&quot; #model modelMiniblocksCue &lt;- lme4::lmer(formula = formulaMiniblocks, data=subset_RA) summary(modelMiniblocksCue) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeAngle ~ cue * mini + (1 + mini:cueMM | ID) ## Data: subset_RA ## ## REML criterion at convergence: 244.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.42202 -0.73920 -0.01271 0.78223 2.56892 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.0009083 0.03014 ## mini:cueMM 0.0003613 0.01901 -0.01 ## Residual 0.0654597 0.25585 ## Number of obs: 1704, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.376687 0.010091 37.329 ## cueboundary 0.209439 0.012397 16.894 ## mini -0.070822 0.008441 -8.391 ## cueboundary:mini 0.095652 0.012773 7.489 ## ## Correlation of Fixed Effects: ## (Intr) cbndry mini ## cueboundary -0.612 ## mini 0.003 -0.002 ## cuebndry:mn -0.003 0.001 -0.754 To test the significance of the interaction, we ran a likelihood ratio test comparing our model and a model with both cue and miniblock as predictors but without the interaction. #control model formulaMiniControl &lt;- &quot;relativeAngle ~ mini+cueMM + (1+mini:cueMM|ID)&quot; modelMiniControlInt &lt;- lme4::lmer(formula = formulaMiniControl, data=subset_RA) #likelihood ratio test ratioMiniblocksInt &lt;- anova(modelMiniblocksCue, modelMiniControlInt) ## refitting model(s) with ML (instead of REML) ratioMiniblocksInt ## Data: subset_RA ## Models: ## modelMiniControlInt: relativeAngle ~ mini + cueMM + (1 + mini:cueMM | ID) ## modelMiniblocksCue: relativeAngle ~ cue * mini + (1 + mini:cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelMiniControlInt 7 262.67 300.76 -124.34 248.67 ## modelMiniblocksCue 8 230.40 273.93 -107.20 214.40 34.27 1 4.796e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Cue specific analysis To check whether miniblocks are a significant predictor without the cue we ran a model and likelihood ratio test separately for landmark-dependent and boundary-dependent objects. #landmark-dependent objects only model formulaMiniblocksAngle &lt;- &quot;relativeAngle ~ mini + (1+mini|ID)&quot; modelMiniblocksLandmarkAngle &lt;- lme4::lmer(formula = formulaMiniblocksAngle, data=subset(subset_RA, cue==&quot;landmark&quot;)) summary(modelMiniblocksLandmarkAngle) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeAngle ~ mini + (1 + mini | ID) ## Data: subset(subset_RA, cue == &quot;landmark&quot;) ## ## REML criterion at convergence: 84.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.0970 -0.7382 -0.1704 0.6549 2.6269 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.0065871 0.08116 ## mini 0.0004987 0.02233 -0.12 ## Residual 0.0597955 0.24453 ## Number of obs: 855, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.376888 0.015907 23.693 ## mini -0.070415 0.008354 -8.429 ## ## Correlation of Fixed Effects: ## (Intr) ## mini -0.044 #control model formulaMiniControl &lt;- &quot;relativeAngle ~ 1 + (1+mini|ID)&quot; modelMiniLandmarkControl &lt;- lme4::lmer(formula = formulaMiniControl, data=subset(subset_RA, cue==&quot;landmark&quot;)) #likelihood ratio test ratioMiniLandmark = anova(modelMiniblocksLandmarkAngle, modelMiniLandmarkControl) ## refitting model(s) with ML (instead of REML) ratioMiniLandmark ## Data: subset(subset_RA, cue == &quot;landmark&quot;) ## Models: ## modelMiniLandmarkControl: relativeAngle ~ 1 + (1 + mini | ID) ## modelMiniblocksLandmarkAngle: relativeAngle ~ mini + (1 + mini | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelMiniLandmarkControl 5 119.927 143.68 -54.963 109.927 ## modelMiniblocksLandmarkAngle 6 82.126 110.63 -35.063 70.126 39.801 1 2.812e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #boundary-dependent objects only model formulaMiniblocksAngle &lt;- &quot;relativeAngle ~ mini + (1+mini|ID)&quot; modelMiniblocksBoundaryAngle &lt;- lme4::lmer(formula = formulaMiniblocksAngle, data=subset(subset_RA,cue==&quot;boundary&quot;)) ## boundary (singular) fit: see ?isSingular summary(modelMiniblocksBoundaryAngle) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeAngle ~ mini + (1 + mini | ID) ## Data: subset(subset_RA, cue == &quot;boundary&quot;) ## ## REML criterion at convergence: 121.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.4410 -0.7082 0.1388 0.8008 1.7816 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 1.533e-03 0.039157 ## mini 1.107e-05 0.003327 -1.00 ## Residual 6.528e-02 0.255494 ## Number of obs: 849, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.585938 0.010934 53.589 ## mini 0.024825 0.007868 3.155 ## ## Correlation of Fixed Effects: ## (Intr) ## mini -0.042 ## optimizer (nloptwrap) convergence code: 0 (OK) ## boundary (singular) fit: see ?isSingular #control model formulaMiniControl &lt;- &quot;relativeAngle ~ 1 + (1+mini|ID)&quot; modelMiniBoundaryControl &lt;- lme4::lmer(formula = formulaMiniControl, data=subset(subset_RA, cue==&quot;boundary&quot;)) #likelihood ratio test ratioMiniBoundary = anova(modelMiniblocksBoundaryAngle, modelMiniBoundaryControl) ## refitting model(s) with ML (instead of REML) ratioMiniBoundary ## Data: subset(subset_RA, cue == &quot;boundary&quot;) ## Models: ## modelMiniBoundaryControl: relativeAngle ~ 1 + (1 + mini | ID) ## modelMiniblocksBoundaryAngle: relativeAngle ~ mini + (1 + mini | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelMiniBoundaryControl 5 125.38 149.10 -57.688 115.38 ## modelMiniblocksBoundaryAngle 6 118.31 146.77 -53.153 106.31 9.0693 1 0.002599 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Cue Dissonance As we decided to recode relative influence score to dCorrect / (dCorrect + dOther), we ran the main model with miniblocks again with the new dependent variable, cue dissonance, to see if the slope differ despite the same direction of improvement. Random effects could not included interaction as this caused singular fit. #model with new recoded dependent variable - cue dissonance formulaCueDis_mini &lt;- &quot;cueDissonanceAngle ~ cueMM*mini + (1+mini+cueMM||ID)&quot; modelCueDis_mini &lt;- lme4::lmer(formula = formulaCueDis_mini, data=subset_RA) summary(modelCueDis_mini) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: cueDissonanceAngle ~ cueMM * mini + ((1 | ID) + (0 + mini | ID) + (0 + cueMM | ID)) ## Data: subset_RA ## ## REML criterion at convergence: 209.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.9915 -0.7631 -0.1706 0.6854 2.5095 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.0030797 0.05550 ## ID.1 mini 0.0004250 0.02062 ## ID.2 cueMM 0.0009844 0.03138 ## Residual 0.0623152 0.24963 ## Number of obs: 1704, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.395369 0.011054 35.767 ## cueMM 0.018623 0.007998 2.329 ## mini -0.047577 0.006411 -7.422 ## cueMM:mini 0.022968 0.005411 4.245 ## ## Correlation of Fixed Effects: ## (Intr) cueMM mini ## cueMM 0.002 ## mini 0.001 -0.001 ## cueMM:mini -0.001 0.001 0.004 To test the significance of the interaction, we ran a likelihood ratio test comparing our model and a model with both cue and miniblock as predictors but without the interaction. #control model for interaction formulaCueDis_miniControl &lt;- &quot;cueDissonanceAngle ~ cueMM+mini + (1+mini+cueMM|ID)&quot; modelCueDis_miniControl &lt;- lme4::lmer(formula = formulaCueDis_miniControl, data=subset_RA) #likelihood ratio test ratioCueDis_mini &lt;- anova(modelCueDis_mini, modelCueDis_miniControl) ## refitting model(s) with ML (instead of REML) ratioCueDis_mini ## Data: subset_RA ## Models: ## modelCueDis_mini: cueDissonanceAngle ~ cueMM * mini + ((1 | ID) + (0 + mini | ID) + (0 + cueMM | ID)) ## modelCueDis_miniControl: cueDissonanceAngle ~ cueMM + mini + (1 + mini + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelCueDis_mini 8 193.84 237.36 -88.918 177.84 ## modelCueDis_miniControl 10 210.05 264.45 -95.023 190.05 0 2 1 To see whether the model including cue is better than a miniblock with random effect we ran a likelihood ratio test. #control model formulaJustCue &lt;- &quot;cueDissonanceAngle ~ mini + (1+mini+cueMM|ID)&quot; modelJustCue &lt;- lme4::lmer(formula = formulaJustCue, data=subset_RA) summary(modelJustCue) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: cueDissonanceAngle ~ mini + (1 + mini + cueMM | ID) ## Data: subset_RA ## ## REML criterion at convergence: 210.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.0315 -0.7643 -0.1797 0.6708 2.5323 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.0031530 0.05615 ## mini 0.0004072 0.02018 -0.07 ## cueMM 0.0012671 0.03560 -0.68 0.01 ## Residual 0.0629721 0.25094 ## Number of obs: 1704, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.405206 0.010233 39.599 ## mini -0.047725 0.006396 -7.462 ## ## Correlation of Fixed Effects: ## (Intr) ## mini -0.033 #likelihood ratio test ratioMini &lt;- anova(modelCueDis_miniControl, modelJustCue) ## refitting model(s) with ML (instead of REML) ratioMini ## Data: subset_RA ## Models: ## modelJustCue: cueDissonanceAngle ~ mini + (1 + mini + cueMM | ID) ## modelCueDis_miniControl: cueDissonanceAngle ~ cueMM + mini + (1 + mini + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelJustCue 9 213.19 262.16 -97.596 195.19 ## modelCueDis_miniControl 10 210.05 264.45 -95.023 190.05 5.1452 1 0.02331 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.6 Age To test our main hypothesis, we ran mixed model including age and cue as main predictors with interaction. 4.6.1 Relative Influence Mixed Model As our initial dependent variable, we examine these two predictors (cue, age) first to relative influence scores. #full model formulaFullAngle &lt;- &quot;relativeAngle ~ age_c*cueMM+(1+cueMM|ID)&quot; modelFullAngle &lt;- lme4::lmer(formula = formulaFullAngle, data=subset_RA) summary(modelFullAngle) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeAngle ~ age_c * cueMM + (1 + cueMM | ID) ## Data: subset_RA ## ## REML criterion at convergence: 297.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.32017 -0.76515 0.00571 0.75640 2.71957 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.0009869 0.03142 ## cueMM 0.0028550 0.05343 -0.76 ## Residual 0.0664093 0.25770 ## Number of obs: 1704, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.4813375 0.0081548 59.025 ## age_c 0.0001364 0.0035434 0.038 ## cueMM 0.1037453 0.0108838 9.532 ## age_c:cueMM 0.0076379 0.0047236 1.617 ## ## Correlation of Fixed Effects: ## (Intr) age_c cueMM ## age_c -0.036 ## cueMM -0.398 0.009 ## age_c:cueMM 0.009 -0.395 -0.032 The significance of the interaction was tested using likelihood ratio test. #control model controlFullAngle &lt;- &quot;relativeAngle ~ age_c+cueMM+(1+cueMM|ID)&quot; modelControlAngle &lt;- lme4::lmer(formula = controlFullAngle, data=subset_RA) #likelihood ratio test ratioFinalAngle &lt;- anova(modelFullAngle, modelControlAngle) ## refitting model(s) with ML (instead of REML) ratioFinalAngle ## Data: subset_RA ## Models: ## modelControlAngle: relativeAngle ~ age_c + cueMM + (1 + cueMM | ID) ## modelFullAngle: relativeAngle ~ age_c * cueMM + (1 + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelControlAngle 7 280.09 318.17 -133.04 266.09 ## modelFullAngle 8 279.42 322.94 -131.71 263.42 2.6715 1 0.1022 Cue specific analysis To see if age remains a significant predictor without cue, we ran mixed models separately for boundary-dependent and landmark-dependent objects and tested them with likelihood ratio test including only random intercepts for participants. #landmark-dependent objects only model formulaAgeLandmark &lt;- &quot;relativeAngle ~ age_c + (1|ID)&quot; modelAgeLandmark &lt;- lme4::lmer(formula = formulaAgeLandmark, data=subset(subset_RA, cue==&quot;landmark&quot;)) summary(modelAgeLandmark) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeAngle ~ age_c + (1 | ID) ## Data: subset(subset_RA, cue == &quot;landmark&quot;) ## ## REML criterion at convergence: 167.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.7349 -0.8084 -0.1823 0.6595 2.6945 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.006381 0.07988 ## Residual 0.066803 0.25846 ## Number of obs: 855, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.377666 0.015992 23.615 ## age_c -0.007531 0.006936 -1.086 ## ## Correlation of Fixed Effects: ## (Intr) ## age_c -0.031 #control model controlAgeLandmark &lt;- &quot;relativeAngle ~ 1 + (1 |ID)&quot; modelControlAgeLandmark &lt;- lme4::lmer(formula = controlAgeLandmark, data=subset(subset_RA, cue==&quot;landmark&quot;)) #likelihood ratio test ratioAgeLandmark &lt;- anova(modelAgeLandmark, modelControlAgeLandmark) ## refitting model(s) with ML (instead of REML) ratioAgeLandmark ## Data: subset(subset_RA, cue == &quot;landmark&quot;) ## Models: ## modelControlAgeLandmark: relativeAngle ~ 1 + (1 | ID) ## modelAgeLandmark: relativeAngle ~ age_c + (1 | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelControlAgeLandmark 3 160.53 174.79 -77.266 154.53 ## modelAgeLandmark 4 161.31 180.31 -76.653 153.31 1.2255 1 0.2683 #boundary-dependent objects only model formulaAgeBoundary &lt;- &quot;relativeAngle ~ age_c +(1|ID)&quot; modelAgeBoundary &lt;- lme4::lmer(formula = formulaAgeBoundary, data=subset(subset_RA, cue==&quot;boundary&quot;)) summary(modelAgeBoundary) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: relativeAngle ~ age_c + (1 | ID) ## Data: subset(subset_RA, cue == &quot;boundary&quot;) ## ## REML criterion at convergence: 129.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.3189 -0.6866 0.1488 0.7803 1.6966 ## ## Random effects: ## Groups Name Variance Std.Dev. ## ID (Intercept) 0.001317 0.03629 ## Residual 0.066006 0.25692 ## Number of obs: 849, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.585204 0.010704 54.673 ## age_c 0.007669 0.004658 1.646 ## ## Correlation of Fixed Effects: ## (Intr) ## age_c -0.040 #control model controlAgeBoundary &lt;- &quot;relativeAngle ~ 1 + (1 |ID)&quot; modelControlAgeBoundary &lt;- lme4::lmer(formula = controlAgeBoundary, data=subset(subset_RA, cue==&quot;boundary&quot;)) #likelihood ratio test ratioAgeBoundary &lt;- anova(modelAgeBoundary, modelControlAgeBoundary) ## refitting model(s) with ML (instead of REML) ratioAgeBoundary ## Data: subset(subset_RA, cue == &quot;boundary&quot;) ## Models: ## modelControlAgeBoundary: relativeAngle ~ 1 + (1 | ID) ## modelAgeBoundary: relativeAngle ~ age_c + (1 | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelControlAgeBoundary 3 122.34 136.58 -58.172 116.34 ## modelAgeBoundary 4 121.58 140.56 -56.793 113.58 2.7586 1 0.09673 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Graphs The graph below visualizes how the relative influence improves with age as seen in collected data. RA_final &lt;- ggplot(relativeAngleBlocks, aes(age, relativeAng, color=cue)) + theme_cowplot() + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, guide = &quot;none&quot;) + stat_summary(fun.data = mean_se,geom=&quot;errorbar&quot;, size=0.8, width=0.1, alpha=0.95) + stat_summary(fun=mean, aes(group=cue), geom=&quot;line&quot;, size = 1.5) + stat_summary(fun=mean, aes(group=cue), geom=&quot;point&quot;, size = 2) + new_scale_color() + geom_point(data = relativeAngleBlocks, aes(color=cue)) + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.3, end=0.7, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_x_continuous(breaks = c(8,9,10,11,12,13,14,15)) + scale_y_continuous(limits = c(0.2, 0.8), breaks = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)) + labs(x= &quot;Age&quot;, y = &quot;Relative Influence (0-1)&quot;, title = &quot;Data&quot;, color=&quot;Cue&quot;) + geom_hline(yintercept = 0.5, linetype=2, alpha=0.6) RA_final The graph below visualizes the relative influence age-dependent improvement based on a mixed model predictions. # calculating values predicted by the mixed model RA_predict &lt;- ggeffects::ggpredict(modelFullAngle, terms = c(&quot;age_c&quot;, &quot;cueMM&quot;)) %&gt;% as_tibble() %&gt;% mutate(cuePredict = factor(if_else(group == 1, true = &quot;boundary&quot;, false = &quot;landmark&quot;), levels = c(&quot;boundary&quot;, &quot;landmark&quot;))) RA_model &lt;- ggplot(RA_predict, aes(x = x, y = predicted, colour = cuePredict, fill = cuePredict)) + geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = .2, linetype=0) + geom_line(size = 0.5) + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_fill_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_x_continuous(breaks = sort(unique(Sum_all$age_c)), labels = c(&quot;8&quot;, &quot;9&quot;, &quot;10&quot;, &quot;11&quot;, &quot;12&quot;, &quot;13&quot;, &quot;14&quot;, &quot;15&quot;)) + scale_y_continuous(breaks = c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8), limits = c(0.2, 0.8)) + theme_cowplot() + labs(x=&quot;Age&quot;, y=&quot; &quot;, color=&quot;Cue&quot;, fill=&quot;Cue&quot;, title = &quot;Mixed Model&quot;) + theme(legend.position = &quot;none&quot;) + geom_hline(yintercept = 0.5, linetype=2, alpha=0.6) RA_model layout &lt;- &quot; AAAAA#BBBBBB AAAAA#BBBBBB AAAAA#BBBBBB &quot; g_finalAng &lt;- RA_final + RA_model &amp; plot_layout(design=layout) &amp; theme(axis.title = element_text(size = 10), axis.text = element_text(size=10), legend.title = element_text(size=10), legend.text = element_text(size=10), legend.position = &quot;bottom&quot;, plot.title = element_text(size=12, face=&quot;italic&quot;), plot.tag = element_text(size = 10, face=&quot;bold&quot;)) &amp; plot_annotation(title = &#39;Pointing &#39;, theme = theme(plot.title = element_text(size = 12, face=&quot;bold&quot;)), tag_levels = list(c(&#39;C&#39;, &#39;D&#39;))) g_finalAng ggsave(&quot;relativeInfluence_finalAng.pdf&quot;, plot=g_finalAng, units = &quot;cm&quot;, width = 15, height = 9, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;relativeInfluence_finalAng.png&quot;, plot=g_finalAng, units = &quot;cm&quot;, width = 15, height = 9, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) 4.6.2 Cue dissonance Mixed Model Next, we tested whether the effect of age and age and cue interaction remain when using the new variable - cue dissonance (one direction recoded relative influence score) as dependent variable. formulaCueDis_A &lt;- &quot;cueDissonanceAngle ~ age_c*cueMM + ( 1 + cueMM | ID)&quot; modelCueDis_A &lt;- lmer(formula = formulaCueDis_A, data=subset_RA) summary(modelCueDis_A) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: cueDissonanceAngle ~ age_c * cueMM + (1 + cueMM | ID) ## Data: subset_RA ## ## REML criterion at convergence: 297.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.7624 -0.7911 -0.1677 0.6991 2.7196 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.002855 0.05343 ## cueMM 0.000987 0.03142 -0.76 ## Residual 0.066409 0.25770 ## Number of obs: 1704, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.3962547 0.0108840 36.407 ## age_c -0.0076379 0.0047237 -1.617 ## cueMM 0.0186625 0.0081550 2.288 ## age_c:cueMM -0.0001363 0.0035434 -0.038 ## ## Correlation of Fixed Effects: ## (Intr) age_c cueMM ## age_c -0.032 ## cueMM -0.398 0.009 ## age_c:cueMM 0.009 -0.395 -0.036 #control model for interaction controlCueDis_A &lt;- &quot;cueDissonanceAngle ~ age_c + cueMM + (1 + cueMM | ID)&quot; modelControlCueDis_A &lt;- lmer(formula = controlCueDis_A, data=subset_RA) #likelihood ratio test ratioCueDis_A &lt;- anova(modelCueDis_A, modelControlCueDis_A) ## refitting model(s) with ML (instead of REML) ratioCueDis_A ## Data: subset_RA ## Models: ## modelControlCueDis_A: cueDissonanceAngle ~ age_c + cueMM + (1 + cueMM | ID) ## modelCueDis_A: cueDissonanceAngle ~ age_c * cueMM + (1 + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelControlCueDis_A 7 277.42 315.50 -131.71 263.42 ## modelCueDis_A 8 279.42 322.94 -131.71 263.42 0.0019 1 0.9653 Explorative Is cue even significant predictor? #control model for cue as predictor controlCueDis_cueA &lt;- &quot;cueDissonanceAngle ~ age_c + (1 + cueMM | ID)&quot; modelCueDis_cueControlA &lt;- lmer(formula = controlCueDis_cueA, data=subset_RA) #likelihood ratio test ratioCueDis_cueA &lt;- anova(modelCueDis_cueControlA, modelControlCueDis_A) ## refitting model(s) with ML (instead of REML) ratioCueDis_cueA ## Data: subset_RA ## Models: ## modelCueDis_cueControlA: cueDissonanceAngle ~ age_c + (1 + cueMM | ID) ## modelControlCueDis_A: cueDissonanceAngle ~ age_c + cueMM + (1 + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelCueDis_cueControlA 6 280.57 313.21 -134.28 268.57 ## modelControlCueDis_A 7 277.42 315.50 -131.71 263.42 5.1478 1 0.02328 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Adding miniblock as a predictor instead to find the best model. #control model for miniblock as predictor miniFullCueDis_A&lt;- &quot;cueDissonanceAngle ~ age_c + mini + (1 + cueMM | ID)&quot; modelCueDis_miniFullA &lt;- lmer(formula = miniFullCueDis_A, data=subset_RA) summary(modelCueDis_miniFullA) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: cueDissonanceAngle ~ age_c + mini + (1 + cueMM | ID) ## Data: subset_RA ## ## REML criterion at convergence: 218.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.9326 -0.7665 -0.1832 0.6878 2.6731 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## ID (Intercept) 0.002940 0.05422 ## cueMM 0.001247 0.03532 -0.72 ## Residual 0.063496 0.25198 ## Number of obs: 1704, groups: ID, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.406107 0.009932 40.890 ## age_c -0.007625 0.004316 -1.767 ## mini -0.047753 0.005461 -8.744 ## ## Correlation of Fixed Effects: ## (Intr) age_c ## age_c -0.036 ## mini 0.001 -0.001 #likelihood ratio test ratioCueDis_fullMiniA &lt;- anova(modelCueDis_miniFullA, modelCueDis_cueControlA) ## refitting model(s) with ML (instead of REML) ratioCueDis_fullMiniA ## Data: subset_RA ## Models: ## modelCueDis_cueControlA: cueDissonanceAngle ~ age_c + (1 + cueMM | ID) ## modelCueDis_miniFullA: cueDissonanceAngle ~ age_c + mini + (1 + cueMM | ID) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## modelCueDis_cueControlA 6 280.57 313.21 -134.283 268.57 ## modelCueDis_miniFullA 7 207.75 245.83 -96.874 193.75 74.819 1 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Graphs The graph below visualizes how the cue dissonance improves with age as seen in collected data. CueDisA_final &lt;- ggplot(relativeAngleBlocks, aes(age, cueDisA, color=cue)) + theme_cowplot() + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, guide = FALSE) + stat_summary(fun=mean, aes(group=cue), geom=&quot;line&quot;, size = 1.5) + stat_summary(fun=mean, aes(group=cue), geom=&quot;point&quot;, size = 2) + stat_summary(fun.data=mean_se, aes(group=cue), geom=&quot;errorbar&quot;, size=0.8, width=0.1, alpha=0.95) + new_scale_color() + geom_point(aes(color=cue)) + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.3, end=0.7, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_x_continuous(breaks = c(8,9,10,11,12,13,14,15)) + scale_y_continuous(limits = c(0.2, 0.8), breaks = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)) + labs(x= &quot;Age&quot;, y = &quot;Cue Dissonance (0-1)&quot;, title = &quot;Data&quot;, color=&quot;Cue&quot;) + geom_hline(yintercept = 0.5, linetype=2, alpha=0.6) CueDisA_final ## Warning: It is deprecated to specify `guide = FALSE` to remove a guide. Please use `guide = &quot;none&quot;` instead. The graph below visualizes the cue dissonance age-dependent improvement based on a mixed model predictions. CueDisA_predict &lt;- ggeffects::ggpredict(modelCueDis_A, terms = c(&quot;age_c&quot;, &quot;cueMM&quot;)) %&gt;% as_tibble() %&gt;% mutate(cuePredict = factor(if_else(group == 1, true = &quot;boundary&quot;, false = &quot;landmark&quot;), levels = c(&quot;boundary&quot;, &quot;landmark&quot;))) CueDisA_model &lt;- ggplot(CueDisA_predict, aes(x = x, y = predicted, colour = cuePredict, fill = cuePredict)) + geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = .2, linetype=0) + geom_line(size = 0.5) + scale_color_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_fill_scico_d(palette = &#39;tokyo&#39;, begin=0.2, end=0.8, labels = c(&quot;Boundary&quot;, &quot;Landmark&quot;)) + scale_x_continuous(breaks = sort(unique(Sum_all$age_c)), labels = c(&quot;8&quot;, &quot;9&quot;, &quot;10&quot;, &quot;11&quot;, &quot;12&quot;, &quot;13&quot;, &quot;14&quot;, &quot;15&quot;)) + scale_y_continuous(breaks = c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8), limits = c(0.2, 0.8)) + theme_cowplot() + labs(x=&quot;Age&quot;, y=&quot; &quot;, color=&quot;Cue&quot;, fill=&quot;Cue&quot;, title = &quot;Mixed Model&quot;) + theme(legend.position = &quot;none&quot;) + geom_hline(yintercept = 0.5, linetype=2, alpha=0.6) CueDisA_model Assembly of the generated graphs. layout &lt;- &quot; AAAAA#BBBBBB AAAAA#BBBBBB AAAAA#BBBBBB &quot; CueDisA_final &lt;- CueDisA_final + CueDisA_model &amp; plot_layout(design=layout) &amp; theme(axis.title = element_text(size = 10), axis.text = element_text(size=10), legend.title = element_text(size=10), legend.text = element_text(size=10), legend.position = &quot;bottom&quot;, plot.title = element_text(size=12, face=&quot;italic&quot;), plot.tag = element_text(size = 10, face=&quot;bold&quot;)) &amp; plot_annotation(title = &#39;Pointing&#39;, theme = theme(plot.title = element_text(size = 12, face=&quot;bold&quot;)), tag_levels = list(c(&#39;A&#39;, &#39;B&#39;))) CueDisA_final ggsave(&quot;cueDissonance_fullAngle.pdf&quot;, plot=CueDisA_final, units = &quot;cm&quot;, width = 15, height = 9, dpi = &quot;retina&quot;, device = cairo_pdf, path = here(&quot;figures&quot;)) ggsave(&quot;cueDissonance_fullAngle.png&quot;, plot=CueDisA_final, units = &quot;cm&quot;, width = 15, height = 9, dpi = &quot;retina&quot;, device = &quot;png&quot;, path = here(&quot;figures&quot;)) "]]
